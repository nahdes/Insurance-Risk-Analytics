{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b20d676",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from scipy.stats import chi2_contingency, ttest_ind, f_oneway\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "import xgboost as xgb\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da0905d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "ALPHACARE INSURANCE SOLUTIONS - COMPLETE ANALYSIS PIPELINE\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Set style for better visualizations\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"ALPHACARE INSURANCE SOLUTIONS - COMPLETE ANALYSIS PIPELINE\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c3af6a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'UnderwrittenCoverID|PolicyID|TransactionMonth|IsVATRegistered|Citizenship|LegalType|Title|Language|Bank|AccountType|MaritalStatus|Gender|Country|Province|PostalCode|MainCrestaZone|SubCrestaZone|ItemType|mmcode|VehicleType|RegistrationYear|make|Model|Cylinders|cubiccapacity|kilowatts|bodytype|NumberOfDoors|VehicleIntroDate|CustomValueEstimate|AlarmImmobiliser|TrackingDevice|CapitalOutstanding|NewVehicle|WrittenOff|Rebuilt|Converted|CrossBorder|NumberOfVehiclesInFleet|SumInsured|TermFrequency|CalculatedPremiumPerTerm|ExcessSelected|CoverCategory|CoverType|CoverGroup|Section|Product|StatutoryClass|StatutoryRiskType|TotalPremium|TotalClaims\\n'\n",
      "'145249|12827|2015-03-01 00:00:00|True|  |Close Corporation|Mr|English|First National Bank|Current account|Not specified|Not specified|South Africa|Gauteng|1459|Rand East|Rand East|Mobility - Motor|44069150|Passenger Vehicle|2004|MERCEDES-BENZ|E 240|6|2597|130|S/D|4|6/2002|119300|Yes|No|119300|More than 6 months||||||0.01|Monthly|25|Mobility - Windscreen|Windscreen|Windscreen|Comprehensive - Taxi|Motor Comprehensive|Mobility Metered Taxis: Monthly|Commercial|IFRS Constant|21.929824561403|.000000000000\\n'\n",
      "'145249|12827|2015-05-01 00:00:00|True|  |Close Corporation|Mr|English|First National Bank|Current account|Not specified|Not specified|South Africa|Gauteng|1459|Rand East|Rand East|Mobility - Motor|44069150|Passenger Vehicle|2004|MERCEDES-BENZ|E 240|6|2597|130|S/D|4|6/2002|119300|Yes|No|119300|More than 6 months||||||0.01|Monthly|25|Mobility - Windscreen|Windscreen|Windscreen|Comprehensive - Taxi|Motor Comprehensive|Mobility Metered Taxis: Monthly|Commercial|IFRS Constant|21.929824561403|.000000000000\\n'\n",
      "'145249|12827|2015-07-01 00:00:00|True|  |Close Corporation|Mr|English|First National Bank|Current account|Not specified|Not specified|South Africa|Gauteng|1459|Rand East|Rand East|Mobility - Motor|44069150|Passenger Vehicle|2004|MERCEDES-BENZ|E 240|6|2597|130|S/D|4|6/2002|119300|Yes|No|119300|More than 6 months||||||0.01|Monthly|25|Mobility - Windscreen|Windscreen|Windscreen|Comprehensive - Taxi|Motor Comprehensive|Mobility Metered Taxis: Monthly|Commercial|IFRS Constant|.000000000000|.000000000000\\n'\n",
      "'145255|12827|2015-05-01 00:00:00|True|  |Close Corporation|Mr|English|First National Bank|Current account|Not specified|Not specified|South Africa|Gauteng|1459|Rand East|Rand East|Mobility - Motor|44069150|Passenger Vehicle|2004|MERCEDES-BENZ|E 240|6|2597|130|S/D|4|6/2002|119300|Yes|No|119300|More than 6 months||||||119300|Monthly|584.6468|Mobility - Metered Taxis - R2000|Own damage|Own Damage|Comprehensive - Taxi|Motor Comprehensive|Mobility Metered Taxis: Monthly|Commercial|IFRS Constant|512.848070175439|.000000000000\\n'\n"
     ]
    }
   ],
   "source": [
    "# Peek at first few lines\n",
    "with open('./Data/MachineLearningRating_v3.txt', 'r') as f:\n",
    "    for i, line in enumerate(f):\n",
    "        if i < 5:  # Show first 5 lines\n",
    "            print(repr(line))  # repr() shows hidden characters like tabs\n",
    "        else:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "302ca83b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "TASK 1: EXPLORATORY DATA ANALYSIS & STATISTICAL THINKING\n",
      "================================================================================\n",
      "\n",
      "[1.1] Loading data...\n",
      "Data loaded successfully!\n",
      "Dataset shape: (1000098, 52)\n",
      "\n",
      "[1.2] Data Understanding - Basic Information\n",
      "--------------------------------------------------------------------------------\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000098 entries, 0 to 1000097\n",
      "Data columns (total 52 columns):\n",
      " #   Column                    Non-Null Count    Dtype  \n",
      "---  ------                    --------------    -----  \n",
      " 0   UnderwrittenCoverID       1000098 non-null  int64  \n",
      " 1   PolicyID                  1000098 non-null  int64  \n",
      " 2   TransactionMonth          1000098 non-null  object \n",
      " 3   IsVATRegistered           1000098 non-null  bool   \n",
      " 4   Citizenship               1000098 non-null  object \n",
      " 5   LegalType                 1000098 non-null  object \n",
      " 6   Title                     1000098 non-null  object \n",
      " 7   Language                  1000098 non-null  object \n",
      " 8   Bank                      854137 non-null   object \n",
      " 9   AccountType               959866 non-null   object \n",
      " 10  MaritalStatus             991839 non-null   object \n",
      " 11  Gender                    990562 non-null   object \n",
      " 12  Country                   1000098 non-null  object \n",
      " 13  Province                  1000098 non-null  object \n",
      " 14  PostalCode                1000098 non-null  int64  \n",
      " 15  MainCrestaZone            1000098 non-null  object \n",
      " 16  SubCrestaZone             1000098 non-null  object \n",
      " 17  ItemType                  1000098 non-null  object \n",
      " 18  mmcode                    999546 non-null   float64\n",
      " 19  VehicleType               999546 non-null   object \n",
      " 20  RegistrationYear          1000098 non-null  int64  \n",
      " 21  make                      999546 non-null   object \n",
      " 22  Model                     999546 non-null   object \n",
      " 23  Cylinders                 999546 non-null   float64\n",
      " 24  cubiccapacity             999546 non-null   float64\n",
      " 25  kilowatts                 999546 non-null   float64\n",
      " 26  bodytype                  999546 non-null   object \n",
      " 27  NumberOfDoors             999546 non-null   float64\n",
      " 28  VehicleIntroDate          999546 non-null   object \n",
      " 29  CustomValueEstimate       220456 non-null   float64\n",
      " 30  AlarmImmobiliser          1000098 non-null  object \n",
      " 31  TrackingDevice            1000098 non-null  object \n",
      " 32  CapitalOutstanding        1000096 non-null  object \n",
      " 33  NewVehicle                846803 non-null   object \n",
      " 34  WrittenOff                358197 non-null   object \n",
      " 35  Rebuilt                   358197 non-null   object \n",
      " 36  Converted                 358197 non-null   object \n",
      " 37  CrossBorder               698 non-null      object \n",
      " 38  NumberOfVehiclesInFleet   0 non-null        float64\n",
      " 39  SumInsured                1000098 non-null  float64\n",
      " 40  TermFrequency             1000098 non-null  object \n",
      " 41  CalculatedPremiumPerTerm  1000098 non-null  float64\n",
      " 42  ExcessSelected            1000098 non-null  object \n",
      " 43  CoverCategory             1000098 non-null  object \n",
      " 44  CoverType                 1000098 non-null  object \n",
      " 45  CoverGroup                1000098 non-null  object \n",
      " 46  Section                   1000098 non-null  object \n",
      " 47  Product                   1000098 non-null  object \n",
      " 48  StatutoryClass            1000098 non-null  object \n",
      " 49  StatutoryRiskType         1000098 non-null  object \n",
      " 50  TotalPremium              1000098 non-null  float64\n",
      " 51  TotalClaims               1000098 non-null  float64\n",
      "dtypes: bool(1), float64(11), int64(4), object(36)\n",
      "memory usage: 390.1+ MB\n",
      "None\n",
      "\n",
      "First few rows:\n",
      "   UnderwrittenCoverID  PolicyID     TransactionMonth  IsVATRegistered  \\\n",
      "0               145249     12827  2015-03-01 00:00:00             True   \n",
      "1               145249     12827  2015-05-01 00:00:00             True   \n",
      "2               145249     12827  2015-07-01 00:00:00             True   \n",
      "3               145255     12827  2015-05-01 00:00:00             True   \n",
      "4               145255     12827  2015-07-01 00:00:00             True   \n",
      "\n",
      "  Citizenship          LegalType Title Language                 Bank  \\\n",
      "0              Close Corporation    Mr  English  First National Bank   \n",
      "1              Close Corporation    Mr  English  First National Bank   \n",
      "2              Close Corporation    Mr  English  First National Bank   \n",
      "3              Close Corporation    Mr  English  First National Bank   \n",
      "4              Close Corporation    Mr  English  First National Bank   \n",
      "\n",
      "       AccountType  ...                    ExcessSelected CoverCategory  \\\n",
      "0  Current account  ...             Mobility - Windscreen    Windscreen   \n",
      "1  Current account  ...             Mobility - Windscreen    Windscreen   \n",
      "2  Current account  ...             Mobility - Windscreen    Windscreen   \n",
      "3  Current account  ...  Mobility - Metered Taxis - R2000    Own damage   \n",
      "4  Current account  ...  Mobility - Metered Taxis - R2000    Own damage   \n",
      "\n",
      "    CoverType            CoverGroup              Section  \\\n",
      "0  Windscreen  Comprehensive - Taxi  Motor Comprehensive   \n",
      "1  Windscreen  Comprehensive - Taxi  Motor Comprehensive   \n",
      "2  Windscreen  Comprehensive - Taxi  Motor Comprehensive   \n",
      "3  Own Damage  Comprehensive - Taxi  Motor Comprehensive   \n",
      "4  Own Damage  Comprehensive - Taxi  Motor Comprehensive   \n",
      "\n",
      "                           Product StatutoryClass StatutoryRiskType  \\\n",
      "0  Mobility Metered Taxis: Monthly     Commercial     IFRS Constant   \n",
      "1  Mobility Metered Taxis: Monthly     Commercial     IFRS Constant   \n",
      "2  Mobility Metered Taxis: Monthly     Commercial     IFRS Constant   \n",
      "3  Mobility Metered Taxis: Monthly     Commercial     IFRS Constant   \n",
      "4  Mobility Metered Taxis: Monthly     Commercial     IFRS Constant   \n",
      "\n",
      "   TotalPremium TotalClaims  \n",
      "0     21.929825         0.0  \n",
      "1     21.929825         0.0  \n",
      "2      0.000000         0.0  \n",
      "3    512.848070         0.0  \n",
      "4      0.000000         0.0  \n",
      "\n",
      "[5 rows x 52 columns]\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# TASK 1: EXPLORATORY DATA ANALYSIS & STATISTICAL THINKING\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TASK 1: EXPLORATORY DATA ANALYSIS & STATISTICAL THINKING\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Load the data\n",
    "print(\"\\n[1.1] Loading data...\")\n",
    "df = pd.read_csv('./Data/MachineLearningRating_v3.txt', sep='|',encoding='utf-8-sig') \n",
    "\n",
    "\n",
    "\n",
    "print(\"Data loaded successfully!\")\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "\n",
    "print(\"\\n[1.2] Data Understanding - Basic Information\")\n",
    "print(\"-\" * 80)\n",
    "print(df.info())\n",
    "print(\"\\nFirst few rows:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "406a133d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[1.3] Data Quality Assessment\n",
      "--------------------------------------------------------------------------------\n",
      "Data Quality Report:\n",
      "                                          Column Data_Type  Missing_Count  \\\n",
      "NumberOfVehiclesInFleet  NumberOfVehiclesInFleet   float64        1000098   \n",
      "CrossBorder                          CrossBorder    object         999400   \n",
      "CustomValueEstimate          CustomValueEstimate   float64         779642   \n",
      "WrittenOff                            WrittenOff    object         641901   \n",
      "Converted                              Converted    object         641901   \n",
      "Rebuilt                                  Rebuilt    object         641901   \n",
      "NewVehicle                            NewVehicle    object         153295   \n",
      "Bank                                        Bank    object         145961   \n",
      "AccountType                          AccountType    object          40232   \n",
      "Gender                                    Gender    object           9536   \n",
      "MaritalStatus                      MaritalStatus    object           8259   \n",
      "mmcode                                    mmcode   float64            552   \n",
      "VehicleType                          VehicleType    object            552   \n",
      "make                                        make    object            552   \n",
      "VehicleIntroDate                VehicleIntroDate    object            552   \n",
      "NumberOfDoors                      NumberOfDoors   float64            552   \n",
      "bodytype                                bodytype    object            552   \n",
      "kilowatts                              kilowatts   float64            552   \n",
      "cubiccapacity                      cubiccapacity   float64            552   \n",
      "Cylinders                              Cylinders   float64            552   \n",
      "Model                                      Model    object            552   \n",
      "CapitalOutstanding            CapitalOutstanding    object              2   \n",
      "\n",
      "                         Missing_Percentage  Unique_Values  \\\n",
      "NumberOfVehiclesInFleet              100.00              0   \n",
      "CrossBorder                           99.93              1   \n",
      "CustomValueEstimate                   77.96            923   \n",
      "WrittenOff                            64.18              2   \n",
      "Converted                             64.18              2   \n",
      "Rebuilt                               64.18              2   \n",
      "NewVehicle                            15.33              2   \n",
      "Bank                                  14.59             11   \n",
      "AccountType                            4.02              3   \n",
      "Gender                                 0.95              3   \n",
      "MaritalStatus                          0.83              3   \n",
      "mmcode                                 0.06            427   \n",
      "VehicleType                            0.06              5   \n",
      "make                                   0.06             46   \n",
      "VehicleIntroDate                       0.06            174   \n",
      "NumberOfDoors                          0.06              6   \n",
      "bodytype                               0.06             13   \n",
      "kilowatts                              0.06             82   \n",
      "cubiccapacity                          0.06            122   \n",
      "Cylinders                              0.06              7   \n",
      "Model                                  0.06            411   \n",
      "CapitalOutstanding                     0.00           1011   \n",
      "\n",
      "                                                             Sample_Values  \n",
      "NumberOfVehiclesInFleet                                                 []  \n",
      "CrossBorder                                                           [No]  \n",
      "CustomValueEstimate                          [119300.0, 161000.0, 52700.0]  \n",
      "WrittenOff                                                       [No, Yes]  \n",
      "Converted                                                        [No, Yes]  \n",
      "Rebuilt                                                          [No, Yes]  \n",
      "NewVehicle                        [More than 6 months, Less than 6 months]  \n",
      "Bank                       [First National Bank, Standard Bank, ABSA Bank]  \n",
      "AccountType              [Current account, Savings account, Transmissio...  \n",
      "Gender                                       [Not specified, Male, Female]  \n",
      "MaritalStatus                             [Not specified, Married, Single]  \n",
      "mmcode                                [44069150.0, 64092300.0, 54057250.0]  \n",
      "VehicleType              [Passenger Vehicle, Medium Commercial, Heavy C...  \n",
      "make                                  [MERCEDES-BENZ, VOLKSWAGEN, RENAULT]  \n",
      "VehicleIntroDate                                  [6/2002, 3/2004, 2/2003]  \n",
      "NumberOfDoors                                              [4.0, 5.0, 2.0]  \n",
      "bodytype                                                   [S/D, SUV, MPV]  \n",
      "kilowatts                                             [130.0, 230.0, 75.0]  \n",
      "cubiccapacity                                     [2597.0, 4921.0, 1870.0]  \n",
      "Cylinders                                                 [6.0, 10.0, 4.0]  \n",
      "Model                    [E 240, TOUAREG 5.0 V10 TDI TIP, SCENIC 1.9 dC...  \n",
      "CapitalOutstanding                                 [119300, 161000, 52700]  \n"
     ]
    }
   ],
   "source": [
    "print(\"\\n[1.3] Data Quality Assessment\")\n",
    "print(\"-\" * 80)\n",
    "# Function to assess data quality\n",
    "def assess_data_quality(df):\n",
    "    \"\"\"Comprehensive data quality assessment\"\"\"\n",
    "    quality_report = pd.DataFrame({\n",
    "        'Column': df.columns,\n",
    "        'Data_Type': df.dtypes,\n",
    "        'Missing_Count': df.isnull().sum(),\n",
    "        'Missing_Percentage': (df.isnull().sum() / len(df) * 100).round(2),\n",
    "        'Unique_Values': df.nunique(),\n",
    "        'Sample_Values': [df[col].dropna().unique()[:3].tolist() if len(df[col].dropna().unique()) > 0 else [] for col in df.columns]\n",
    "    })\n",
    "    \n",
    "    print(\"Data Quality Report:\")\n",
    "    print(quality_report[quality_report.Missing_Count > 0].sort_values('Missing_Percentage', ascending=False))\n",
    "    \n",
    "    return quality_report\n",
    "quality_report = assess_data_quality(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "30004b76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame shape: (1000098, 52)\n",
      "Columns: ['UnderwrittenCoverID', 'PolicyID', 'TransactionMonth', 'IsVATRegistered', 'Citizenship', 'LegalType', 'Title', 'Language', 'Bank', 'AccountType', 'MaritalStatus', 'Gender', 'Country', 'Province', 'PostalCode', 'MainCrestaZone', 'SubCrestaZone', 'ItemType', 'mmcode', 'VehicleType', 'RegistrationYear', 'make', 'Model', 'Cylinders', 'cubiccapacity', 'kilowatts', 'bodytype', 'NumberOfDoors', 'VehicleIntroDate', 'CustomValueEstimate', 'AlarmImmobiliser', 'TrackingDevice', 'CapitalOutstanding', 'NewVehicle', 'WrittenOff', 'Rebuilt', 'Converted', 'CrossBorder', 'NumberOfVehiclesInFleet', 'SumInsured', 'TermFrequency', 'CalculatedPremiumPerTerm', 'ExcessSelected', 'CoverCategory', 'CoverType', 'CoverGroup', 'Section', 'Product', 'StatutoryClass', 'StatutoryRiskType', 'TotalPremium', 'TotalClaims']\n",
      "\n",
      "Total missing values per column:\n",
      "UnderwrittenCoverID               0\n",
      "PolicyID                          0\n",
      "TransactionMonth                  0\n",
      "IsVATRegistered                   0\n",
      "Citizenship                       0\n",
      "LegalType                         0\n",
      "Title                             0\n",
      "Language                          0\n",
      "Bank                         145961\n",
      "AccountType                   40232\n",
      "MaritalStatus                  8259\n",
      "Gender                         9536\n",
      "Country                           0\n",
      "Province                          0\n",
      "PostalCode                        0\n",
      "MainCrestaZone                    0\n",
      "SubCrestaZone                     0\n",
      "ItemType                          0\n",
      "mmcode                          552\n",
      "VehicleType                     552\n",
      "RegistrationYear                  0\n",
      "make                            552\n",
      "Model                           552\n",
      "Cylinders                       552\n",
      "cubiccapacity                   552\n",
      "kilowatts                       552\n",
      "bodytype                        552\n",
      "NumberOfDoors                   552\n",
      "VehicleIntroDate                552\n",
      "CustomValueEstimate          779642\n",
      "AlarmImmobiliser                  0\n",
      "TrackingDevice                    0\n",
      "CapitalOutstanding                2\n",
      "NewVehicle                   153295\n",
      "WrittenOff                   641901\n",
      "Rebuilt                      641901\n",
      "Converted                    641901\n",
      "CrossBorder                  999400\n",
      "NumberOfVehiclesInFleet     1000098\n",
      "SumInsured                        0\n",
      "TermFrequency                     0\n",
      "CalculatedPremiumPerTerm          0\n",
      "ExcessSelected                    0\n",
      "CoverCategory                     0\n",
      "CoverType                         0\n",
      "CoverGroup                        0\n",
      "Section                           0\n",
      "Product                           0\n",
      "StatutoryClass                    0\n",
      "StatutoryRiskType                 0\n",
      "TotalPremium                      0\n",
      "TotalClaims                       0\n",
      "dtype: int64\n",
      "\n",
      "Any missing at all? True\n"
     ]
    }
   ],
   "source": [
    "print(\"DataFrame shape:\", df.shape)\n",
    "print(\"Columns:\", list(df.columns))\n",
    "print(\"\\nTotal missing values per column:\")\n",
    "print(df.isnull().sum())\n",
    "print(\"\\nAny missing at all?\", df.isnull().values.any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "43e24d24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[1.4] Descriptive Statistics\n",
      "--------------------------------------------------------------------------------\n",
      "Descriptive Statistics for Numerical Variables:\n",
      "                              count          mean           std           min  \\\n",
      "UnderwrittenCoverID       1000098.0  1.048175e+05  6.329371e+04  1.000000e+00   \n",
      "PolicyID                  1000098.0  7.956682e+03  5.290039e+03  1.400000e+01   \n",
      "PostalCode                1000098.0  3.020601e+03  2.649854e+03  1.000000e+00   \n",
      "mmcode                     999546.0  5.487770e+07  1.360381e+07  4.041200e+06   \n",
      "RegistrationYear          1000098.0  2.010225e+03  3.261391e+00  1.987000e+03   \n",
      "Cylinders                  999546.0  4.046642e+00  2.940201e-01  0.000000e+00   \n",
      "cubiccapacity              999546.0  2.466743e+03  4.428006e+02  0.000000e+00   \n",
      "kilowatts                  999546.0  9.720792e+01  1.939326e+01  0.000000e+00   \n",
      "NumberOfDoors              999546.0  4.019250e+00  4.683144e-01  0.000000e+00   \n",
      "CustomValueEstimate        220456.0  2.255311e+05  5.645157e+05  2.000000e+04   \n",
      "NumberOfVehiclesInFleet         0.0           NaN           NaN           NaN   \n",
      "SumInsured                1000098.0  6.041727e+05  1.508332e+06  1.000000e-02   \n",
      "CalculatedPremiumPerTerm  1000098.0  1.178757e+02  3.997017e+02  0.000000e+00   \n",
      "TotalPremium              1000098.0  6.190550e+01  2.302845e+02 -7.825768e+02   \n",
      "TotalClaims               1000098.0  6.486119e+01  2.384075e+03 -1.200241e+04   \n",
      "\n",
      "                                   25%           50%           75%  \\\n",
      "UnderwrittenCoverID       5.514300e+04  9.408300e+04  1.391900e+05   \n",
      "PolicyID                  4.500000e+03  7.071000e+03  1.107700e+04   \n",
      "PostalCode                8.270000e+02  2.000000e+03  4.180000e+03   \n",
      "mmcode                    6.005692e+07  6.005842e+07  6.005842e+07   \n",
      "RegistrationYear          2.008000e+03  2.011000e+03  2.013000e+03   \n",
      "Cylinders                 4.000000e+00  4.000000e+00  4.000000e+00   \n",
      "cubiccapacity             2.237000e+03  2.694000e+03  2.694000e+03   \n",
      "kilowatts                 7.500000e+01  1.110000e+02  1.110000e+02   \n",
      "NumberOfDoors             4.000000e+00  4.000000e+00  4.000000e+00   \n",
      "CustomValueEstimate       1.350000e+05  2.200000e+05  2.800000e+05   \n",
      "NumberOfVehiclesInFleet            NaN           NaN           NaN   \n",
      "SumInsured                5.000000e+03  7.500000e+03  2.500000e+05   \n",
      "CalculatedPremiumPerTerm  3.224800e+00  8.436900e+00  9.000000e+01   \n",
      "TotalPremium              0.000000e+00  2.178333e+00  2.192982e+01   \n",
      "TotalClaims               0.000000e+00  0.000000e+00  0.000000e+00   \n",
      "\n",
      "                                   max      variance    skewness      kurtosis  \n",
      "UnderwrittenCoverID       3.011750e+05  4.006094e+09    0.611710      0.028837  \n",
      "PolicyID                  2.324600e+04  2.798451e+07    0.737428      0.281970  \n",
      "PostalCode                9.870000e+03  7.021728e+06    0.799472     -0.636058  \n",
      "mmcode                    6.506535e+07  1.850635e+14   -2.609235      5.615633  \n",
      "RegistrationYear          2.015000e+03  1.063667e+01   -0.794487      0.608084  \n",
      "Cylinders                 1.000000e+01  8.644783e-02    5.704635     71.285271  \n",
      "cubiccapacity             1.288000e+04  1.960724e+05    3.576025    102.289803  \n",
      "kilowatts                 3.090000e+02  3.760984e+02    0.244719      3.009992  \n",
      "NumberOfDoors             6.000000e+00  2.193184e-01   -2.531328     18.833823  \n",
      "CustomValueEstimate       2.655000e+07  3.186780e+11   40.870518   1762.321550  \n",
      "NumberOfVehiclesInFleet            NaN           NaN         NaN           NaN  \n",
      "SumInsured                1.263620e+07  2.275065e+12    2.548565      4.645169  \n",
      "CalculatedPremiumPerTerm  7.442217e+04  1.597615e+05  122.974581  22210.701737  \n",
      "TotalPremium              6.528260e+04  5.303096e+04  138.596458  37176.185477  \n",
      "TotalClaims               3.930921e+05  5.683812e+06   69.933118   6791.926170  \n"
     ]
    }
   ],
   "source": [
    "print(\"\\n[1.4] Descriptive Statistics\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "def calculate_descriptive_stats(df):\n",
    "    \"\"\"Calculate comprehensive descriptive statistics\"\"\"\n",
    "    numerical_cols = df.select_dtypes(include=[np.number]).columns\n",
    "    \n",
    "    stats_summary = df[numerical_cols].describe().T\n",
    "    stats_summary['variance'] = df[numerical_cols].var()\n",
    "    stats_summary['skewness'] = df[numerical_cols].skew()\n",
    "    stats_summary['kurtosis'] = df[numerical_cols].kurtosis()\n",
    "    \n",
    "    print(\"Descriptive Statistics for Numerical Variables:\")\n",
    "    print(stats_summary)\n",
    "    \n",
    "    return stats_summary\n",
    "stats_summary = calculate_descriptive_stats(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c6557b82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[1.5] Key Business Metrics Calculation\n",
      "--------------------------------------------------------------------------------\n",
      "Overall Business Metrics:\n",
      "Total_Premium: 61,911,562.70\n",
      "Total_Claims: 64,867,546.17\n",
      "Overall_Loss_Ratio: 104.77%\n",
      "Number_of_Policies: 7,000.00\n",
      "Claim_Frequency: 0.28%\n",
      "Average_Premium: 61.91\n",
      "Average_Claim: 23,273.39\n",
      "Total_Margin: -2,955,983.47\n",
      "\n",
      "\n",
      "Loss Ratio by Province:\n",
      "                TotalClaims  TotalPremium  PolicyID  LossRatio\n",
      "Province                                                      \n",
      "Gauteng        2.939415e+07  2.405377e+07    393865   1.222018\n",
      "KwaZulu-Natal  1.430138e+07  1.320908e+07    169781   1.082693\n",
      "Western Cape   1.038977e+07  9.806559e+06    170796   1.059472\n",
      "North West     5.920250e+06  7.490508e+06    143287   0.790367\n",
      "Mpumalanga     2.044675e+06  2.836292e+06     52718   0.720897\n",
      "Free State     3.549223e+05  5.213632e+05      8099   0.680758\n",
      "Limpopo        1.016477e+06  1.537324e+06     24836   0.661199\n",
      "Eastern Cape   1.356427e+06  2.140104e+06     30336   0.633813\n",
      "Northern Cape  8.949051e+04  3.165581e+05      6380   0.282699\n",
      "\n",
      "\n",
      "Loss Ratio by Vehicle Type:\n",
      "                    TotalClaims  TotalPremium  PolicyID  LossRatio\n",
      "VehicleType                                                       \n",
      "Heavy Commercial   7.504746e+05  4.609479e+05      7401   1.628112\n",
      "Medium Commercial  4.119867e+06  3.922746e+06     53985   1.050251\n",
      "Passenger Vehicle  5.937207e+07  5.664202e+07    933598   1.048198\n",
      "Light Commercial   6.045250e+04  2.604975e+05      3897   0.232066\n",
      "Bus                7.996535e+03  5.824474e+04       665   0.137292\n",
      "\n",
      "\n",
      "Loss Ratio by Gender:\n",
      "                TotalClaims  TotalPremium  PolicyID  LossRatio\n",
      "Gender                                                        \n",
      "Female         2.502461e+05  3.044806e+05      6755   0.821879\n",
      "Male           1.396704e+06  1.580143e+06     42817   0.883910\n",
      "Not specified  6.271410e+07  5.920275e+07    940990   1.059311\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n[1.5] Key Business Metrics Calculation\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "def calculate_business_metrics(df):\n",
    "    \"\"\"Calculate key insurance business metrics\"\"\"\n",
    "    \n",
    "    # Overall metrics\n",
    "    overall_metrics = {\n",
    "        'Total_Premium': df['TotalPremium'].sum(),\n",
    "        'Total_Claims': df['TotalClaims'].sum(),\n",
    "        'Overall_Loss_Ratio': df['TotalClaims'].sum() / df['TotalPremium'].sum(),\n",
    "        'Number_of_Policies': df['PolicyID'].nunique(),\n",
    "        'Claim_Frequency': (df['TotalClaims'] > 0).mean(),\n",
    "        'Average_Premium': df['TotalPremium'].mean(),\n",
    "        'Average_Claim': df[df['TotalClaims'] > 0]['TotalClaims'].mean(),\n",
    "        'Total_Margin': (df['TotalPremium'] - df['TotalClaims']).sum()\n",
    "    }\n",
    "    \n",
    "    print(\"Overall Business Metrics:\")\n",
    "    for metric, value in overall_metrics.items():\n",
    "        if 'Ratio' in metric or 'Frequency' in metric:\n",
    "            print(f\"{metric}: {value:.2%}\")\n",
    "        else:\n",
    "            print(f\"{metric}: {value:,.2f}\")\n",
    "    \n",
    "    # Loss ratio by Province\n",
    "    print(\"\\n\\nLoss Ratio by Province:\")\n",
    "    loss_by_province = df.groupby('Province').agg({\n",
    "        'TotalClaims': 'sum',\n",
    "        'TotalPremium': 'sum',\n",
    "        'PolicyID': 'count'\n",
    "    })\n",
    "    loss_by_province['LossRatio'] = loss_by_province['TotalClaims'] / loss_by_province['TotalPremium']\n",
    "    loss_by_province = loss_by_province.sort_values('LossRatio', ascending=False)\n",
    "    print(loss_by_province)\n",
    "    \n",
    "    # Loss ratio by VehicleType\n",
    "    print(\"\\n\\nLoss Ratio by Vehicle Type:\")\n",
    "    loss_by_vehicle = df.groupby('VehicleType').agg({\n",
    "        'TotalClaims': 'sum',\n",
    "        'TotalPremium': 'sum',\n",
    "        'PolicyID': 'count'\n",
    "    })\n",
    "    loss_by_vehicle['LossRatio'] = loss_by_vehicle['TotalClaims'] / loss_by_vehicle['TotalPremium']\n",
    "    loss_by_vehicle = loss_by_vehicle.sort_values('LossRatio', ascending=False)\n",
    "    print(loss_by_vehicle)\n",
    "    \n",
    "    # Loss ratio by Gender\n",
    "    print(\"\\n\\nLoss Ratio by Gender:\")\n",
    "    loss_by_gender = df.groupby('Gender').agg({\n",
    "        'TotalClaims': 'sum',\n",
    "        'TotalPremium': 'sum',\n",
    "        'PolicyID': 'count'\n",
    "    })\n",
    "    loss_by_gender['LossRatio'] = loss_by_gender['TotalClaims'] / loss_by_gender['TotalPremium']\n",
    "    print(loss_by_gender)\n",
    "    \n",
    "    return overall_metrics, loss_by_province, loss_by_vehicle, loss_by_gender\n",
    "\n",
    "overall_metrics, loss_by_province, loss_by_vehicle, loss_by_gender = calculate_business_metrics(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d876a312",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[1.6] Univariate Analysis - Distributions\n",
      "--------------------------------------------------------------------------------\n",
      "Saved: univariate_distributions.png\n",
      "Saved: boxplots_outliers.png\n",
      "Saved: categorical_distributions.png\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n[1.6] Univariate Analysis - Distributions\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "def univariate_analysis(df):\n",
    "    \"\"\"Perform univariate analysis with visualizations\"\"\"\n",
    "    \n",
    "    numerical_cols = ['TotalPremium', 'TotalClaims', 'SumInsured', \n",
    "                      'CalculatedPremiumPerTerm', 'CustomValueEstimate']\n",
    "    \n",
    "    # Histograms\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "    axes = axes.ravel()\n",
    "    \n",
    "    for idx, col in enumerate(numerical_cols):\n",
    "        if col in df.columns:\n",
    "            axes[idx].hist(df[col].dropna(), bins=50, edgecolor='black', alpha=0.7)\n",
    "            axes[idx].set_title(f'Distribution of {col}', fontsize=12, fontweight='bold')\n",
    "            axes[idx].set_xlabel(col)\n",
    "            axes[idx].set_ylabel('Frequency')\n",
    "            axes[idx].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('univariate_distributions.png', dpi=300, bbox_inches='tight')\n",
    "    print(\"Saved: univariate_distributions.png\")\n",
    "    plt.close()\n",
    "    \n",
    "    # Box plots for outlier detection\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "    \n",
    "    for idx, col in enumerate(['TotalPremium', 'TotalClaims', 'CustomValueEstimate']):\n",
    "        if col in df.columns:\n",
    "            axes[idx].boxplot(df[col].dropna())\n",
    "            axes[idx].set_title(f'Box Plot: {col}', fontsize=12, fontweight='bold')\n",
    "            axes[idx].set_ylabel(col)\n",
    "            axes[idx].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('boxplots_outliers.png', dpi=300, bbox_inches='tight')\n",
    "    print(\"Saved: boxplots_outliers.png\")\n",
    "    plt.close()\n",
    "    \n",
    "    # Categorical variables\n",
    "    categorical_cols = ['Province', 'VehicleType', 'Gender', 'CoverType']\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "    axes = axes.ravel()\n",
    "    \n",
    "    for idx, col in enumerate(categorical_cols):\n",
    "        if col in df.columns:\n",
    "            value_counts = df[col].value_counts().head(10)\n",
    "            axes[idx].bar(range(len(value_counts)), value_counts.values)\n",
    "            axes[idx].set_xticks(range(len(value_counts)))\n",
    "            axes[idx].set_xticklabels(value_counts.index, rotation=45, ha='right')\n",
    "            axes[idx].set_title(f'Distribution of {col}', fontsize=12, fontweight='bold')\n",
    "            axes[idx].set_ylabel('Count')\n",
    "            axes[idx].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('categorical_distributions.png', dpi=300, bbox_inches='tight')\n",
    "    print(\"Saved: categorical_distributions.png\")\n",
    "    plt.close()\n",
    "\n",
    "univariate_analysis(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "506022f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[1.7] Bivariate and Multivariate Analysis\n",
      "--------------------------------------------------------------------------------\n",
      "Saved: correlation_matrix.png\n",
      "Saved: premium_vs_claims_postal.png\n",
      "Saved: temporal_trends.png\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n[1.7] Bivariate and Multivariate Analysis\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "def bivariate_analysis(df):\n",
    "    \"\"\"Perform bivariate and multivariate analysis\"\"\"\n",
    "    \n",
    "    # Correlation matrix\n",
    "    numerical_cols = ['TotalPremium', 'TotalClaims', 'SumInsured', \n",
    "                      'CalculatedPremiumPerTerm', 'CustomValueEstimate']\n",
    "    \n",
    "    if all(col in df.columns for col in numerical_cols):\n",
    "        corr_matrix = df[numerical_cols].corr()\n",
    "        \n",
    "        plt.figure(figsize=(12, 10))\n",
    "        sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', center=0, \n",
    "                    square=True, linewidths=1, cbar_kws={\"shrink\": 0.8})\n",
    "        plt.title('Correlation Matrix - Key Financial Variables', fontsize=14, fontweight='bold')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig('correlation_matrix.png', dpi=300, bbox_inches='tight')\n",
    "        print(\"Saved: correlation_matrix.png\")\n",
    "        plt.close()\n",
    "    \n",
    "    # Premium vs Claims by PostalCode\n",
    "    postal_analysis = df.groupby('PostalCode').agg({\n",
    "        'TotalPremium': 'sum',\n",
    "        'TotalClaims': 'sum'\n",
    "    }).reset_index()\n",
    "    \n",
    "    plt.figure(figsize=(14, 8))\n",
    "    plt.scatter(postal_analysis['TotalPremium'], \n",
    "               postal_analysis['TotalClaims'], \n",
    "               alpha=0.6, s=100, edgecolors='black', linewidth=0.5)\n",
    "    plt.xlabel('Total Premium', fontsize=12)\n",
    "    plt.ylabel('Total Claims', fontsize=12)\n",
    "    plt.title('Premium vs Claims by PostalCode', fontsize=14, fontweight='bold')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Add diagonal line\n",
    "    max_val = max(postal_analysis['TotalPremium'].max(), postal_analysis['TotalClaims'].max())\n",
    "    plt.plot([0, max_val], [0, max_val], 'r--', alpha=0.5, label='Break-even line')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('premium_vs_claims_postal.png', dpi=300, bbox_inches='tight')\n",
    "    print(\"Saved: premium_vs_claims_postal.png\")\n",
    "    plt.close()\n",
    "    \n",
    "    # Temporal trends\n",
    "    df['TransactionMonth'] = pd.to_datetime(df['TransactionMonth'])\n",
    "    df['HasClaim'] = (df['TotalClaims'] > 0).astype(int)\n",
    "    \n",
    "    monthly_trends = df.groupby('TransactionMonth').agg({\n",
    "        'TotalClaims': 'sum',\n",
    "        'TotalPremium': 'sum',\n",
    "        'HasClaim': 'mean'\n",
    "    }).reset_index()\n",
    "    \n",
    "    fig, ax1 = plt.subplots(figsize=(16, 8))\n",
    "    ax2 = ax1.twinx()\n",
    "    \n",
    "    ax1.plot(monthly_trends['TransactionMonth'], \n",
    "             monthly_trends['TotalClaims'], \n",
    "             'b-', linewidth=2, label='Total Claims', marker='o')\n",
    "    ax2.plot(monthly_trends['TransactionMonth'], \n",
    "             monthly_trends['HasClaim'], \n",
    "             'r-', linewidth=2, label='Claim Frequency', marker='s')\n",
    "    \n",
    "    ax1.set_xlabel('Month', fontsize=12)\n",
    "    ax1.set_ylabel('Total Claims', color='b', fontsize=12)\n",
    "    ax2.set_ylabel('Claim Frequency', color='r', fontsize=12)\n",
    "    ax1.tick_params(axis='y', labelcolor='b')\n",
    "    ax2.tick_params(axis='y', labelcolor='r')\n",
    "    \n",
    "    plt.title('Temporal Trends in Claims and Frequency', fontsize=14, fontweight='bold')\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    lines1, labels1 = ax1.get_legend_handles_labels()\n",
    "    lines2, labels2 = ax2.get_legend_handles_labels()\n",
    "    ax1.legend(lines1 + lines2, labels1 + labels2, loc='upper left')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('temporal_trends.png', dpi=300, bbox_inches='tight')\n",
    "    print(\"Saved: temporal_trends.png\")\n",
    "    plt.close()\n",
    "bivariate_analysis(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bff7aabf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[1.8] Outlier Detection\n",
      "--------------------------------------------------------------------------------\n",
      "Outlier Detection Summary (IQR Method):\n",
      "                Column   Lower_Bound    Upper_Bound  Outlier_Count  \\\n",
      "0         TotalPremium    -32.894737      54.824561         209042   \n",
      "1          TotalClaims      0.000000       0.000000           2793   \n",
      "2  CustomValueEstimate -82500.000000  497500.000000           1785   \n",
      "\n",
      "   Outlier_Percentage  \n",
      "0           20.902152  \n",
      "1            0.279273  \n",
      "2            0.178483  \n"
     ]
    }
   ],
   "source": [
    "print(\"\\n[1.8] Outlier Detection\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "def detect_outliers(df):\n",
    "    \"\"\"Detect outliers using IQR method\"\"\"\n",
    "    \n",
    "    numerical_cols = ['TotalPremium', 'TotalClaims', 'CustomValueEstimate']\n",
    "    \n",
    "    outlier_summary = []\n",
    "    \n",
    "    for col in numerical_cols:\n",
    "        if col in df.columns:\n",
    "            Q1 = df[col].quantile(0.25)\n",
    "            Q3 = df[col].quantile(0.75)\n",
    "            IQR = Q3 - Q1\n",
    "            \n",
    "            lower_bound = Q1 - 1.5 * IQR\n",
    "            upper_bound = Q3 + 1.5 * IQR\n",
    "            \n",
    "            outliers = df[(df[col] < lower_bound) | (df[col] > upper_bound)]\n",
    "            \n",
    "            outlier_summary.append({\n",
    "                'Column': col,\n",
    "                'Lower_Bound': lower_bound,\n",
    "                'Upper_Bound': upper_bound,\n",
    "                'Outlier_Count': len(outliers),\n",
    "                'Outlier_Percentage': len(outliers) / len(df) * 100\n",
    "            })\n",
    "    \n",
    "    outlier_df = pd.DataFrame(outlier_summary)\n",
    "    print(\"Outlier Detection Summary (IQR Method):\")\n",
    "    print(outlier_df)\n",
    "    \n",
    "    return outlier_df\n",
    "outlier_df = detect_outliers(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ddf3e7e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_column(df, possible_names):\n",
    "    \"\"\"\n",
    "    Find column in DataFrame by checking multiple possible names (case-insensitive)\n",
    "    \"\"\"\n",
    "    for name in possible_names:\n",
    "        # Check exact match\n",
    "        if name in df.columns:\n",
    "            return name\n",
    "        # Check case-insensitive match\n",
    "        for col in df.columns:\n",
    "            if col.lower() == name.lower():\n",
    "                return col\n",
    "            # Check with spaces/underscores removed\n",
    "            if col.lower().replace(' ', '').replace('_', '') == name.lower().replace(' ', '').replace('_', ''):\n",
    "                return col\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0c9bc611",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[1.9] Creative Visualizations\n",
      "--------------------------------------------------------------------------------\n",
      "Column mapping:\n",
      "  ✓ Province        -> Province\n",
      "  ✓ VehicleType     -> VehicleType\n",
      "  ✓ TotalClaims     -> TotalClaims\n",
      "  ✓ TotalPremium    -> TotalPremium\n",
      "  ✓ PolicyID        -> PolicyID\n",
      "  ✓ Make            -> make\n",
      "  ✓ Model           -> Model\n",
      "  ✓ PostalCode      -> PostalCode\n",
      "  ✓ Gender          -> Gender\n",
      "Saved: creative_viz_1_risk_heatmap.png\n",
      "Saved: creative_viz_2_profitability.png\n",
      "Saved: creative_viz_3_segmentation.png\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n[1.9] Creative Visualizations\")\n",
    "print(\"-\" * 80)\n",
    "def create_creative_visualizations(df):\n",
    "    # Reuse column mapping logic\n",
    "    col_map = {\n",
    "        'Province': find_column(df, ['Province']),\n",
    "        'VehicleType': find_column(df, ['VehicleType']),\n",
    "        'TotalClaims': find_column(df, ['TotalClaims']),\n",
    "        'TotalPremium': find_column(df, ['TotalPremium']),\n",
    "        'PolicyID': find_column(df, ['PolicyID', 'UnderwrittenCoverID']),\n",
    "        'Make': find_column(df, ['Make']),\n",
    "        'Model': find_column(df, ['Model']),\n",
    "        'PostalCode': find_column(df, ['PostalCode']),\n",
    "        'Gender': find_column(df, ['Gender']),\n",
    "    }\n",
    "\n",
    "    print(\"Column mapping:\")\n",
    "    for k, v in col_map.items():\n",
    "        print(f\"  {'✓' if v else '✗'} {k:15s} -> {v}\")\n",
    "\n",
    "    # Visualization 1\n",
    "    if col_map['Province'] and col_map['VehicleType'] and col_map['TotalClaims']:\n",
    "        pivot_data = df.pivot_table(\n",
    "            values=col_map['TotalClaims'],\n",
    "            index=col_map['Province'],\n",
    "            columns=col_map['VehicleType'],\n",
    "            aggfunc='mean'\n",
    "        )\n",
    "        plt.figure(figsize=(14, 8))\n",
    "        sns.heatmap(pivot_data, annot=True, fmt='.0f', cmap='RdYlGn_r', \n",
    "                    linewidths=0.5, cbar_kws={'label': 'Average Claim Amount'})\n",
    "        plt.title('Risk Profile: Average Claim Amount by Province and Vehicle Type', \n",
    "                  fontsize=14, fontweight='bold')\n",
    "        plt.xlabel('Vehicle Type', fontsize=12)\n",
    "        plt.ylabel('Province', fontsize=12)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig('creative_viz_1_risk_heatmap.png', dpi=300, bbox_inches='tight')\n",
    "        print(\"Saved: creative_viz_1_risk_heatmap.png\")\n",
    "        plt.close()\n",
    "    else:\n",
    "        print(\"Skipping Visualization 1: missing required columns\")\n",
    "\n",
    "    # Visualization 2\n",
    "    if all(col_map[k] for k in ['TotalPremium','TotalClaims','Province','PolicyID']):\n",
    "        df_viz2 = df.copy()\n",
    "        df_viz2['Margin'] = df_viz2[col_map['TotalPremium']] - df_viz2[col_map['TotalClaims']]\n",
    "        province_profit = df_viz2.groupby(col_map['Province']).agg({\n",
    "            'Margin': 'sum',\n",
    "            col_map['TotalPremium']: 'sum',\n",
    "            col_map['PolicyID']: 'count'\n",
    "        }).reset_index()\n",
    "        province_profit.columns = ['Province', 'Margin', 'TotalPremium', 'PolicyCount']\n",
    "        province_profit['AvgMarginPerPolicy'] = province_profit['Margin'] / province_profit['PolicyCount']\n",
    "        province_profit = province_profit.sort_values('AvgMarginPerPolicy', ascending=False)\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(18, 7))\n",
    "        colors = ['#2ecc71' if x > 0 else '#e74c3c' for x in province_profit['AvgMarginPerPolicy']]\n",
    "        ax1.barh(province_profit['Province'], province_profit['AvgMarginPerPolicy'], color=colors, alpha=0.7)\n",
    "        ax1.set_xlabel('Average Margin per Policy', fontsize=12)\n",
    "        ax1.set_title('Profitability by Province', fontsize=13, fontweight='bold')\n",
    "        ax1.axvline(x=0, color='black', linestyle='--', linewidth=1)\n",
    "        ax1.grid(True, alpha=0.3)\n",
    "        ax2.scatter(province_profit['TotalPremium'], province_profit['Margin'], \n",
    "                   s=province_profit['PolicyCount']*3, alpha=0.6, c=colors, edgecolors='black')\n",
    "        ax2.set_xlabel('Total Premium', fontsize=12)\n",
    "        ax2.set_ylabel('Total Margin', fontsize=12)\n",
    "        ax2.set_title('Premium vs Margin (size = policy count)', fontsize=13, fontweight='bold')\n",
    "        ax2.grid(True, alpha=0.3)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig('creative_viz_2_profitability.png', dpi=300, bbox_inches='tight')\n",
    "        print(\"Saved: creative_viz_2_profitability.png\")\n",
    "        plt.close()\n",
    "    else:\n",
    "        print(\"Skipping Visualization 2: missing required columns\")\n",
    "\n",
    "    # Visualization 3\n",
    "    if col_map['Make'] and col_map['TotalClaims'] and col_map['TotalPremium'] and col_map['PolicyID']:\n",
    "        groupby_cols = [col_map['Make']]\n",
    "        if col_map['Model']:\n",
    "            groupby_cols.append(col_map['Model'])\n",
    "        vehicle_analysis = df.groupby(groupby_cols).agg({\n",
    "            col_map['TotalClaims']: 'sum',\n",
    "            col_map['TotalPremium']: 'sum',\n",
    "            col_map['PolicyID']: 'count'\n",
    "        }).reset_index()\n",
    "        suffix = ['TotalClaims','TotalPremium','PolicyCount']\n",
    "        vehicle_analysis.columns = groupby_cols + suffix\n",
    "        vehicle_analysis = vehicle_analysis[vehicle_analysis['PolicyCount'] >= 5]  # relaxed threshold\n",
    "        if len(vehicle_analysis) > 0:\n",
    "            vehicle_analysis['LossRatio'] = vehicle_analysis['TotalClaims'] / vehicle_analysis['TotalPremium']\n",
    "            vehicle_analysis['AvgPremium'] = vehicle_analysis['TotalPremium'] / vehicle_analysis['PolicyCount']\n",
    "            vehicle_analysis = vehicle_analysis[(vehicle_analysis['LossRatio'] >= 0) & (vehicle_analysis['LossRatio'] < 5)]\n",
    "            if len(vehicle_analysis) > 0:\n",
    "                plt.figure(figsize=(16, 10))\n",
    "                scatter = plt.scatter(vehicle_analysis['AvgPremium'], \n",
    "                                     vehicle_analysis['LossRatio'],\n",
    "                                     s=vehicle_analysis['PolicyCount']*5,\n",
    "                                     c=vehicle_analysis['LossRatio'],\n",
    "                                     cmap='RdYlGn_r',\n",
    "                                     alpha=0.6,\n",
    "                                     edgecolors='black',\n",
    "                                     linewidth=0.5)\n",
    "                plt.colorbar(scatter, label='Loss Ratio')\n",
    "                plt.xlabel('Average Premium per Policy', fontsize=12)\n",
    "                plt.ylabel('Loss Ratio', fontsize=12)\n",
    "                title = f'Customer Segmentation: Risk vs Value ({\" and \".join(groupby_cols)})'\n",
    "                plt.title(title, fontsize=14, fontweight='bold')\n",
    "                plt.axhline(y=1.0, color='red', linestyle='--', linewidth=1, alpha=0.5, label='Break-even')\n",
    "                plt.axvline(x=vehicle_analysis['AvgPremium'].median(), color='blue', \n",
    "                           linestyle='--', linewidth=1, alpha=0.5, label='Median Premium')\n",
    "                plt.legend()\n",
    "                plt.grid(True, alpha=0.3)\n",
    "                plt.tight_layout()\n",
    "                plt.savefig('creative_viz_3_segmentation.png', dpi=300, bbox_inches='tight')\n",
    "                print(\"Saved: creative_viz_3_segmentation.png\")\n",
    "                plt.close()\n",
    "            else:\n",
    "                print(\"Skipping Visualization 3: insufficient valid data after filtering\")\n",
    "        else:\n",
    "            print(\"Skipping Visualization 3: too few vehicle groups\")\n",
    "    else:\n",
    "        print(\"Skipping Visualization 3: missing Make/TotalClaims/TotalPremium/PolicyID\")\n",
    "\n",
    "create_creative_visualizations(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "506d0f1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column mapping:\n",
      "  ✓ Province        -> Province\n",
      "  ✓ VehicleType     -> VehicleType\n",
      "  ✓ TotalClaims     -> TotalClaims\n",
      "  ✓ TotalPremium    -> TotalPremium\n",
      "  ✓ PolicyID        -> PolicyID\n",
      "  ✓ Make            -> make\n",
      "  ✓ Model           -> Model\n",
      "  ✓ PostalCode      -> PostalCode\n",
      "  ✓ Gender          -> Gender\n",
      "Saved: creative_viz_1_risk_heatmap.png\n",
      "Saved: creative_viz_2_profitability.png\n",
      "Saved: creative_viz_3_segmentation.png\n"
     ]
    }
   ],
   "source": [
    "create_creative_visualizations(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4020dbae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "TASK 3: A/B HYPOTHESIS TESTING\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# TASK 3: A/B HYPOTHESIS TESTING\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TASK 3: A/B HYPOTHESIS TESTING\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "def prepare_hypothesis_testing_data(df):\n",
    "    \"\"\"Prepare data for hypothesis testing\"\"\"\n",
    "    df['HasClaim'] = (df['TotalClaims'] > 0).astype(int)\n",
    "    df['ClaimFrequency'] = df.groupby('PostalCode')['HasClaim'].transform('mean')\n",
    "    df['ClaimSeverity'] = df[df['TotalClaims'] > 0].groupby('PostalCode')['TotalClaims'].transform('mean')\n",
    "    df['Margin'] = df['TotalPremium'] - df['TotalClaims']\n",
    "    \n",
    "    return df\n",
    "df = prepare_hypothesis_testing_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ccd5916f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[3.1] Hypothesis Test 1: Risk Differences Across Provinces\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n[3.1] Hypothesis Test 1: Risk Differences Across Provinces\")\n",
    "print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c47c1c49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing: H0 - No risk differences across provinces\n",
      "Method: Chi-squared test for claim frequency\n",
      "\n",
      "Chi-squared statistic: 104.1909\n",
      "P-value: 0.000000\n",
      "Degrees of freedom: 8\n",
      "\n",
      "✓ REJECT H0 (p-value 0.000000 < 0.05)\n",
      "Conclusion: There ARE significant risk differences across provinces\n",
      "\n",
      "Claim Frequency by Province:\n",
      "               Claim_Frequency  Policy_Count\n",
      "Province                                    \n",
      "Gauteng                 0.0034        393865\n",
      "KwaZulu-Natal           0.0028        169781\n",
      "Limpopo                 0.0027         24836\n",
      "North West              0.0024        143287\n",
      "Mpumalanga              0.0024         52718\n",
      "Western Cape            0.0022        170796\n",
      "Eastern Cape            0.0016         30336\n",
      "Free State              0.0014          8099\n",
      "Northern Cape           0.0013          6380\n"
     ]
    }
   ],
   "source": [
    "def test_province_risk(df):\n",
    "    \"\"\"\n",
    "    H0: There are no risk differences across provinces\n",
    "    Risk = Claim Frequency\n",
    "    \"\"\"\n",
    "    print(\"Testing: H0 - No risk differences across provinces\")\n",
    "    print(\"Method: Chi-squared test for claim frequency\")\n",
    "    \n",
    "    # Create contingency table\n",
    "    contingency_table = pd.crosstab(df['Province'], df['HasClaim'])\n",
    "    \n",
    "    # Chi-squared test\n",
    "    chi2, p_value, dof, expected = chi2_contingency(contingency_table)\n",
    "    \n",
    "    print(f\"\\nChi-squared statistic: {chi2:.4f}\")\n",
    "    print(f\"P-value: {p_value:.6f}\")\n",
    "    print(f\"Degrees of freedom: {dof}\")\n",
    "    \n",
    "    alpha = 0.05\n",
    "    if p_value < alpha:\n",
    "        print(f\"\\n✓ REJECT H0 (p-value {p_value:.6f} < {alpha})\")\n",
    "        print(\"Conclusion: There ARE significant risk differences across provinces\")\n",
    "    else:\n",
    "        print(f\"\\n✗ FAIL TO REJECT H0 (p-value {p_value:.6f} >= {alpha})\")\n",
    "        print(\"Conclusion: No significant risk differences across provinces\")\n",
    "    \n",
    "    # Show claim frequencies by province\n",
    "    print(\"\\nClaim Frequency by Province:\")\n",
    "    province_risk = df.groupby('Province').agg({\n",
    "        'HasClaim': 'mean',\n",
    "        'PolicyID': 'count'\n",
    "    }).round(4)\n",
    "    province_risk.columns = ['Claim_Frequency', 'Policy_Count']\n",
    "    print(province_risk.sort_values('Claim_Frequency', ascending=False))\n",
    "    \n",
    "    return chi2, p_value\n",
    "chi2_province, p_value_province = test_province_risk(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5c929044",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[3.2] Hypothesis Test 2: Risk Differences Between Zip Codes\n",
      "--------------------------------------------------------------------------------\n",
      "Testing: H0 - No risk differences between zip codes\n",
      "Method: ANOVA (using top 20 zip codes by policy count)\n",
      "\n",
      "F-statistic: 5.6436\n",
      "P-value: 0.000000\n",
      "\n",
      "✓ REJECT H0 (p-value 0.000000 < 0.05)\n",
      "Conclusion: There ARE significant risk differences between zip codes\n",
      "\n",
      "Top 10 Highest Risk Zip Codes:\n",
      "            Claim_Frequency  Policy_Count\n",
      "PostalCode                               \n",
      "466                0.055556            18\n",
      "2920               0.054545            55\n",
      "1126               0.028571            70\n",
      "1751               0.025974            77\n",
      "181                0.025316           158\n",
      "721                0.025000           120\n",
      "4027               0.024793           121\n",
      "1665               0.024390            82\n",
      "1947               0.022472            89\n",
      "31                 0.022222           135\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n[3.2] Hypothesis Test 2: Risk Differences Between Zip Codes\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "def test_zipcode_risk(df, sample_size=20):\n",
    "    \"\"\"\n",
    "    H0: There are no risk differences between zip codes\n",
    "    Using ANOVA for multiple groups\n",
    "    \"\"\"\n",
    "    print(f\"Testing: H0 - No risk differences between zip codes\")\n",
    "    print(f\"Method: ANOVA (using top {sample_size} zip codes by policy count)\")\n",
    "    \n",
    "    # Get top zip codes by policy count\n",
    "    top_zipcodes = df['PostalCode'].value_counts().head(sample_size).index\n",
    "    df_sample = df[df['PostalCode'].isin(top_zipcodes)]\n",
    "    \n",
    "    # Prepare groups\n",
    "    groups = [df_sample[df_sample['PostalCode'] == zc]['HasClaim'].values \n",
    "              for zc in top_zipcodes]\n",
    "    \n",
    "    # ANOVA test\n",
    "    f_stat, p_value = f_oneway(*groups)\n",
    "    \n",
    "    print(f\"\\nF-statistic: {f_stat:.4f}\")\n",
    "    print(f\"P-value: {p_value:.6f}\")\n",
    "    \n",
    "    alpha = 0.05\n",
    "    if p_value < alpha:\n",
    "        print(f\"\\n✓ REJECT H0 (p-value {p_value:.6f} < {alpha})\")\n",
    "        print(\"Conclusion: There ARE significant risk differences between zip codes\")\n",
    "    else:\n",
    "        print(f\"\\n✗ FAIL TO REJECT H0 (p-value {p_value:.6f} >= {alpha})\")\n",
    "        print(\"Conclusion: No significant risk differences between zip codes\")\n",
    "    \n",
    "    # Show top and bottom zip codes by risk\n",
    "    print(\"\\nTop 10 Highest Risk Zip Codes:\")\n",
    "    zipcode_risk = df.groupby('PostalCode').agg({\n",
    "        'HasClaim': 'mean',\n",
    "        'PolicyID': 'count'\n",
    "    })\n",
    "    zipcode_risk = zipcode_risk[zipcode_risk['PolicyID'] >= 10]  # Min 10 policies\n",
    "    zipcode_risk.columns = ['Claim_Frequency', 'Policy_Count']\n",
    "    print(zipcode_risk.sort_values('Claim_Frequency', ascending=False).head(10))\n",
    "    \n",
    "    return f_stat, p_value\n",
    "f_stat_zip, p_value_zip = test_zipcode_risk(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0cce7f53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[3.3] Hypothesis Test 3: Margin Differences Between Zip Codes\n",
      "--------------------------------------------------------------------------------\n",
      "Testing: H0 - No significant margin difference between zip codes\n",
      "Method: ANOVA (using top 20 zip codes)\n",
      "\n",
      "F-statistic: 1.8775\n",
      "P-value: 0.011581\n",
      "\n",
      "✓ REJECT H0 (p-value 0.011581 < 0.05)\n",
      "Conclusion: There ARE significant margin differences between zip codes\n",
      "\n",
      "Top 10 Most Profitable Zip Codes:\n",
      "            Avg_Margin  Policy_Count\n",
      "PostalCode                          \n",
      "3887        196.635975            25\n",
      "4016        195.716263            10\n",
      "9744        175.104079            50\n",
      "3802        172.142169            32\n",
      "1423        171.010857           120\n",
      "4319        170.421530            54\n",
      "1932        166.555767            32\n",
      "2021        165.244211            22\n",
      "2055        164.889002            16\n",
      "4140        163.833640            70\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n[3.3] Hypothesis Test 3: Margin Differences Between Zip Codes\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "def test_zipcode_margin(df, sample_size=20):\n",
    "    \"\"\"\n",
    "    H0: There is no significant margin difference between zip codes\n",
    "    Using ANOVA\n",
    "    \"\"\"\n",
    "    print(f\"Testing: H0 - No significant margin difference between zip codes\")\n",
    "    print(f\"Method: ANOVA (using top {sample_size} zip codes)\")\n",
    "    \n",
    "    # Get top zip codes\n",
    "    top_zipcodes = df['PostalCode'].value_counts().head(sample_size).index\n",
    "    df_sample = df[df['PostalCode'].isin(top_zipcodes)]\n",
    "    \n",
    "    # Prepare groups\n",
    "    groups = [df_sample[df_sample['PostalCode'] == zc]['Margin'].values \n",
    "              for zc in top_zipcodes]\n",
    "    \n",
    "    # ANOVA test\n",
    "    f_stat, p_value = f_oneway(*groups)\n",
    "    \n",
    "    print(f\"\\nF-statistic: {f_stat:.4f}\")\n",
    "    print(f\"P-value: {p_value:.6f}\")\n",
    "    \n",
    "    alpha = 0.05\n",
    "    if p_value < alpha:\n",
    "        print(f\"\\n✓ REJECT H0 (p-value {p_value:.6f} < {alpha})\")\n",
    "        print(\"Conclusion: There ARE significant margin differences between zip codes\")\n",
    "    else:\n",
    "        print(f\"\\n✗ FAIL TO REJECT H0 (p-value {p_value:.6f} >= {alpha})\")\n",
    "        print(\"Conclusion: No significant margin differences between zip codes\")\n",
    "    \n",
    "    # Show margin analysis\n",
    "    print(\"\\nTop 10 Most Profitable Zip Codes:\")\n",
    "    zipcode_margin = df.groupby('PostalCode').agg({\n",
    "        'Margin': 'mean',\n",
    "        'PolicyID': 'count'\n",
    "    })\n",
    "    zipcode_margin = zipcode_margin[zipcode_margin['PolicyID'] >= 10]\n",
    "    zipcode_margin.columns = ['Avg_Margin', 'Policy_Count']\n",
    "    print(zipcode_margin.sort_values('Avg_Margin', ascending=False).head(10))\n",
    "    \n",
    "    return f_stat, p_value\n",
    "\n",
    "f_stat_margin, p_value_margin = test_zipcode_margin(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c208067c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[3.4] Hypothesis Test 4: Risk Differences Between Women and Men\n",
      "--------------------------------------------------------------------------------\n",
      "Testing: H0 - No significant risk difference between women and men\n",
      "Method: Two-sample t-test and Chi-squared test\n",
      "\n",
      "Chi-squared Test (Claim Frequency):\n",
      "Chi-squared statistic: 0.0037\n",
      "P-value: 0.951464\n",
      "\n",
      "T-test (Claim Severity):\n",
      "T-statistic: -0.4191\n",
      "P-value: 0.676016\n",
      "\n",
      "✗ FAIL TO REJECT H0\n",
      "Conclusion: No significant risk differences between genders\n",
      "\n",
      "Risk Statistics by Gender:\n",
      "        Claim_Frequency  Avg_Claim  Avg_Premium  Policy_Count\n",
      "Gender                                                       \n",
      "Female           0.0021    37.0461      45.0748          6755\n",
      "Male             0.0022    32.6203      36.9046         42817\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n[3.4] Hypothesis Test 4: Risk Differences Between Women and Men\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "def test_gender_risk(df):\n",
    "    \"\"\"\n",
    "    H0: There is no significant risk difference between women and men\n",
    "    Using two-sample t-test\n",
    "    \"\"\"\n",
    "    print(\"Testing: H0 - No significant risk difference between women and men\")\n",
    "    print(\"Method: Two-sample t-test and Chi-squared test\")\n",
    "    \n",
    "    # Filter data\n",
    "    df_gender = df[df['Gender'].isin(['Male', 'Female'])]\n",
    "    \n",
    "    # Chi-squared test for claim frequency\n",
    "    contingency_table = pd.crosstab(df_gender['Gender'], df_gender['HasClaim'])\n",
    "    chi2, p_value_chi2, dof, expected = chi2_contingency(contingency_table)\n",
    "    \n",
    "    print(f\"\\nChi-squared Test (Claim Frequency):\")\n",
    "    print(f\"Chi-squared statistic: {chi2:.4f}\")\n",
    "    print(f\"P-value: {p_value_chi2:.6f}\")\n",
    "    \n",
    "    # T-test for claim severity (among those who claimed)\n",
    "    df_claimed = df_gender[df_gender['TotalClaims'] > 0]\n",
    "    male_claims = df_claimed[df_claimed['Gender'] == 'Male']['TotalClaims']\n",
    "    female_claims = df_claimed[df_claimed['Gender'] == 'Female']['TotalClaims']\n",
    "    \n",
    "    t_stat, p_value_ttest = ttest_ind(male_claims, female_claims)\n",
    "    \n",
    "    print(f\"\\nT-test (Claim Severity):\")\n",
    "    print(f\"T-statistic: {t_stat:.4f}\")\n",
    "    print(f\"P-value: {p_value_ttest:.6f}\")\n",
    "    \n",
    "    alpha = 0.05\n",
    "    \n",
    "    # Interpretation\n",
    "    if p_value_chi2 < alpha or p_value_ttest < alpha:\n",
    "        print(f\"\\n✓ REJECT H0\")\n",
    "        print(\"Conclusion: There ARE significant risk differences between genders\")\n",
    "    else:\n",
    "        print(f\"\\n✗ FAIL TO REJECT H0\")\n",
    "        print(\"Conclusion: No significant risk differences between genders\")\n",
    "    \n",
    "    # Show statistics by gender\n",
    "    print(\"\\nRisk Statistics by Gender:\")\n",
    "    gender_stats = df_gender.groupby('Gender').agg({\n",
    "        'HasClaim': 'mean',\n",
    "        'TotalClaims': 'mean',\n",
    "        'TotalPremium': 'mean',\n",
    "        'PolicyID': 'count'\n",
    "    }).round(4)\n",
    "    gender_stats.columns = ['Claim_Frequency', 'Avg_Claim', 'Avg_Premium', 'Policy_Count']\n",
    "    print(gender_stats)\n",
    "    \n",
    "    return chi2, p_value_chi2, t_stat, p_value_ttest\n",
    "\n",
    "chi2_gender, p_chi2_gender, t_gender, p_t_gender = test_gender_risk(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f7e83056",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[3.5] Summary of Hypothesis Tests\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Hypothesis Testing Summary:\n",
      "                                 Hypothesis            Test_Type      P_Value       Decision Significance\n",
      "   H0: No risk differences across provinces          Chi-squared 5.925511e-19         Reject          Yes\n",
      "  H0: No risk differences between zip codes                ANOVA 2.590639e-14         Reject          Yes\n",
      "H0: No margin differences between zip codes                ANOVA 1.158103e-02         Reject          Yes\n",
      "    H0: No risk differences between genders Chi-squared & T-test 9.514645e-01 Fail to Reject           No\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n[3.5] Summary of Hypothesis Tests\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "def summarize_hypothesis_tests(results):\n",
    "    \"\"\"Summarize all hypothesis test results\"\"\"\n",
    "    summary = pd.DataFrame({\n",
    "        'Hypothesis': [\n",
    "            'H0: No risk differences across provinces',\n",
    "            'H0: No risk differences between zip codes',\n",
    "            'H0: No margin differences between zip codes',\n",
    "            'H0: No risk differences between genders'\n",
    "        ],\n",
    "        'Test_Type': ['Chi-squared', 'ANOVA', 'ANOVA', 'Chi-squared & T-test'],\n",
    "        'P_Value': results,\n",
    "        'Decision': ['Reject' if p < 0.05 else 'Fail to Reject' for p in results],\n",
    "        'Significance': ['Yes' if p < 0.05 else 'No' for p in results]\n",
    "    })\n",
    "    \n",
    "    print(\"\\nHypothesis Testing Summary:\")\n",
    "    print(summary.to_string(index=False))\n",
    "    \n",
    "    return summary\n",
    "\n",
    "p_values = [p_value_province, p_value_zip, p_value_margin, p_chi2_gender]\n",
    "summary_df = summarize_hypothesis_tests(p_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "77ebf087",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "TASK 4: MACHINE LEARNING & STATISTICAL MODELING\n",
      "================================================================================\n",
      "\n",
      "[4.1] Data Preparation for Modeling\n",
      "--------------------------------------------------------------------------------\n",
      "Preparing data for modeling...\n",
      "Data prepared: (1000098, 59)\n",
      "Features: 59\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# TASK 4: MACHINE LEARNING & STATISTICAL MODELING\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TASK 4: MACHINE LEARNING & STATISTICAL MODELING\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\n[4.1] Data Preparation for Modeling\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "def prepare_modeling_data(df):\n",
    "    \"\"\"Prepare data for machine learning models\"\"\"\n",
    "    \n",
    "    print(\"Preparing data for modeling...\")\n",
    "    \n",
    "    # Create a copy\n",
    "    df_model = df.copy()\n",
    "    \n",
    "    # Feature engineering\n",
    "    df_model['VehicleAge'] = 2015 - df_model['RegistrationYear']\n",
    "    df_model['HasClaim'] = (df_model['TotalClaims'] > 0).astype(int)\n",
    "    df_model['LogPremium'] = np.log1p(df_model['TotalPremium'])\n",
    "    df_model['LogClaims'] = np.log1p(df_model['TotalClaims'])\n",
    "    \n",
    "    # Handle missing values\n",
    "    numerical_cols = df_model.select_dtypes(include=[np.number]).columns\n",
    "    for col in numerical_cols:\n",
    "        df_model[col].fillna(df_model[col].median(), inplace=True)\n",
    "    \n",
    "    categorical_cols = df_model.select_dtypes(include=['object']).columns\n",
    "    for col in categorical_cols:\n",
    "        df_model[col].fillna(df_model[col].mode()[0], inplace=True)\n",
    "    \n",
    "    print(f\"Data prepared: {df_model.shape}\")\n",
    "    print(f\"Features: {df_model.shape[1]}\")\n",
    "    \n",
    "    return df_model\n",
    "df_model = prepare_modeling_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "77ebfe58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[4.2] Feature Selection and Encoding\n",
      "--------------------------------------------------------------------------------\n",
      "Total features for modeling: 13\n",
      "Categorical features encoded: 7\n",
      "Numerical features: 8\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n[4.2] Feature Selection and Encoding\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "def encode_features(df):\n",
    "    \"\"\"Encode categorical features\"\"\"\n",
    "    \n",
    "    df_encoded = df.copy()\n",
    "    \n",
    "    # Select features for modeling\n",
    "    categorical_features = [\n",
    "        'Province', 'VehicleType', 'Make', 'Gender', \n",
    "        'MaritalStatus', 'CoverType', 'AlarmImmobiliser'\n",
    "    ]\n",
    "    \n",
    "    numerical_features = [\n",
    "        'VehicleAge', 'SumInsured', 'CalculatedPremiumPerTerm',\n",
    "        'Cylinders', 'Kilowatts', 'NumberOfDoors', \n",
    "        'CustomValueEstimate', 'CapitalOutstanding'\n",
    "    ]\n",
    "    \n",
    "    # Label encoding for categorical variables\n",
    "    label_encoders = {}\n",
    "    for col in categorical_features:\n",
    "        if col in df_encoded.columns:\n",
    "            le = LabelEncoder()\n",
    "            df_encoded[col + '_encoded'] = le.fit_transform(df_encoded[col].astype(str))\n",
    "            label_encoders[col] = le\n",
    "    \n",
    "    # Create feature list\n",
    "    feature_cols = [col + '_encoded' for col in categorical_features if col in df_encoded.columns]\n",
    "    feature_cols += [col for col in numerical_features if col in df_encoded.columns]\n",
    "    \n",
    "    print(f\"Total features for modeling: {len(feature_cols)}\")\n",
    "    print(f\"Categorical features encoded: {len(categorical_features)}\")\n",
    "    print(f\"Numerical features: {len(numerical_features)}\")\n",
    "    \n",
    "    return df_encoded, feature_cols, label_encoders\n",
    "\n",
    "df_encoded, feature_cols, label_encoders = encode_features(df_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b1d2d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n[4.3] Model 1: Linear Regression for Total Claims (by Zip Code)\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "def linear_regression_by_zipcode(df, feature_cols):\n",
    "    \"\"\"\n",
    "    Fit linear regression model for each zipcode to predict total claims\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"Building Linear Regression models by Zip Code...\")\n",
    "    \n",
    "    # Get top zip codes by policy count\n",
    "    top_zipcodes = df['PostalCode'].value_counts().head(10).index\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for zipcode in top_zipcodes:\n",
    "        df_zip = df[df['PostalCode'] == zipcode].copy()\n",
    "        \n",
    "        if len(df_zip) < 30:  # Skip if too few samples\n",
    "            continue\n",
    "        \n",
    "        # Prepare features and target\n",
    "        X = df_zip[feature_cols].fillna(0)\n",
    "        y = df_zip['TotalClaims']\n",
    "        \n",
    "        # Split data\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y, test_size=0.2, random_state=42\n",
    "        )\n",
    "        \n",
    "        # Train model\n",
    "        model = LinearRegression()\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        # Predictions\n",
    "        y_pred = model.predict(X_test)\n",
    "        \n",
    "        # Metrics\n",
    "        rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "        mae = mean_absolute_error(y_test, y_pred)\n",
    "        \n",
    "        results.append({\n",
    "            'ZipCode': zipcode,\n",
    "            'Sample_Size': len(df_zip),\n",
    "            'RMSE': rmse,\n",
    "            'R2_Score': r2,\n",
    "            'MAE': mae\n",
    "        })\n",
    "        \n",
    "        print(f\"ZipCode {zipcode}: RMSE={rmse:.2f}, R²={r2:.4f}, MAE={mae:.2f}\")\n",
    "    \n",
    "    results_df = pd.DataFrame(results)\n",
    "    print(\"\\nSummary of Linear Regression Models:\")\n",
    "    print(results_df.describe())\n",
    "    \n",
    "    return results_df\n",
    "\n",
    "lr_results = linear_regression_by_zipcode(df_encoded, feature_cols)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv (3.13.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
