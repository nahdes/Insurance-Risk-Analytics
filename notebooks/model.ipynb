{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "76835551",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "import xgboost as xgb\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6aa2280",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "TASK 1: EXPLORATORY DATA ANALYSIS & STATISTICAL THINKING\n",
      "================================================================================\n",
      "\n",
      "[1.1] Loading data...\n",
      "Data loaded successfully!\n",
      "Dataset shape: (1000098, 52)\n",
      "\n",
      "[1.2] Data Understanding - Basic Information\n",
      "--------------------------------------------------------------------------------\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000098 entries, 0 to 1000097\n",
      "Data columns (total 52 columns):\n",
      " #   Column                    Non-Null Count    Dtype  \n",
      "---  ------                    --------------    -----  \n",
      " 0   UnderwrittenCoverID       1000098 non-null  int64  \n",
      " 1   PolicyID                  1000098 non-null  int64  \n",
      " 2   TransactionMonth          1000098 non-null  object \n",
      " 3   IsVATRegistered           1000098 non-null  bool   \n",
      " 4   Citizenship               1000098 non-null  object \n",
      " 5   LegalType                 1000098 non-null  object \n",
      " 6   Title                     1000098 non-null  object \n",
      " 7   Language                  1000098 non-null  object \n",
      " 8   Bank                      854137 non-null   object \n",
      " 9   AccountType               959866 non-null   object \n",
      " 10  MaritalStatus             991839 non-null   object \n",
      " 11  Gender                    990562 non-null   object \n",
      " 12  Country                   1000098 non-null  object \n",
      " 13  Province                  1000098 non-null  object \n",
      " 14  PostalCode                1000098 non-null  int64  \n",
      " 15  MainCrestaZone            1000098 non-null  object \n",
      " 16  SubCrestaZone             1000098 non-null  object \n",
      " 17  ItemType                  1000098 non-null  object \n",
      " 18  mmcode                    999546 non-null   float64\n",
      " 19  VehicleType               999546 non-null   object \n",
      " 20  RegistrationYear          1000098 non-null  int64  \n",
      " 21  make                      999546 non-null   object \n",
      " 22  Model                     999546 non-null   object \n",
      " 23  Cylinders                 999546 non-null   float64\n",
      " 24  cubiccapacity             999546 non-null   float64\n",
      " 25  kilowatts                 999546 non-null   float64\n",
      " 26  bodytype                  999546 non-null   object \n",
      " 27  NumberOfDoors             999546 non-null   float64\n",
      " 28  VehicleIntroDate          999546 non-null   object \n",
      " 29  CustomValueEstimate       220456 non-null   float64\n",
      " 30  AlarmImmobiliser          1000098 non-null  object \n",
      " 31  TrackingDevice            1000098 non-null  object \n",
      " 32  CapitalOutstanding        1000096 non-null  object \n",
      " 33  NewVehicle                846803 non-null   object \n",
      " 34  WrittenOff                358197 non-null   object \n",
      " 35  Rebuilt                   358197 non-null   object \n",
      " 36  Converted                 358197 non-null   object \n",
      " 37  CrossBorder               698 non-null      object \n",
      " 38  NumberOfVehiclesInFleet   0 non-null        float64\n",
      " 39  SumInsured                1000098 non-null  float64\n",
      " 40  TermFrequency             1000098 non-null  object \n",
      " 41  CalculatedPremiumPerTerm  1000098 non-null  float64\n",
      " 42  ExcessSelected            1000098 non-null  object \n",
      " 43  CoverCategory             1000098 non-null  object \n",
      " 44  CoverType                 1000098 non-null  object \n",
      " 45  CoverGroup                1000098 non-null  object \n",
      " 46  Section                   1000098 non-null  object \n",
      " 47  Product                   1000098 non-null  object \n",
      " 48  StatutoryClass            1000098 non-null  object \n",
      " 49  StatutoryRiskType         1000098 non-null  object \n",
      " 50  TotalPremium              1000098 non-null  float64\n",
      " 51  TotalClaims               1000098 non-null  float64\n",
      "dtypes: bool(1), float64(11), int64(4), object(36)\n",
      "memory usage: 390.1+ MB\n",
      "None\n",
      "\n",
      "First few rows:\n",
      "   UnderwrittenCoverID  PolicyID     TransactionMonth  IsVATRegistered  \\\n",
      "0               145249     12827  2015-03-01 00:00:00             True   \n",
      "1               145249     12827  2015-05-01 00:00:00             True   \n",
      "2               145249     12827  2015-07-01 00:00:00             True   \n",
      "3               145255     12827  2015-05-01 00:00:00             True   \n",
      "4               145255     12827  2015-07-01 00:00:00             True   \n",
      "\n",
      "  Citizenship          LegalType Title Language                 Bank  \\\n",
      "0              Close Corporation    Mr  English  First National Bank   \n",
      "1              Close Corporation    Mr  English  First National Bank   \n",
      "2              Close Corporation    Mr  English  First National Bank   \n",
      "3              Close Corporation    Mr  English  First National Bank   \n",
      "4              Close Corporation    Mr  English  First National Bank   \n",
      "\n",
      "       AccountType  ...                    ExcessSelected CoverCategory  \\\n",
      "0  Current account  ...             Mobility - Windscreen    Windscreen   \n",
      "1  Current account  ...             Mobility - Windscreen    Windscreen   \n",
      "2  Current account  ...             Mobility - Windscreen    Windscreen   \n",
      "3  Current account  ...  Mobility - Metered Taxis - R2000    Own damage   \n",
      "4  Current account  ...  Mobility - Metered Taxis - R2000    Own damage   \n",
      "\n",
      "    CoverType            CoverGroup              Section  \\\n",
      "0  Windscreen  Comprehensive - Taxi  Motor Comprehensive   \n",
      "1  Windscreen  Comprehensive - Taxi  Motor Comprehensive   \n",
      "2  Windscreen  Comprehensive - Taxi  Motor Comprehensive   \n",
      "3  Own Damage  Comprehensive - Taxi  Motor Comprehensive   \n",
      "4  Own Damage  Comprehensive - Taxi  Motor Comprehensive   \n",
      "\n",
      "                           Product StatutoryClass StatutoryRiskType  \\\n",
      "0  Mobility Metered Taxis: Monthly     Commercial     IFRS Constant   \n",
      "1  Mobility Metered Taxis: Monthly     Commercial     IFRS Constant   \n",
      "2  Mobility Metered Taxis: Monthly     Commercial     IFRS Constant   \n",
      "3  Mobility Metered Taxis: Monthly     Commercial     IFRS Constant   \n",
      "4  Mobility Metered Taxis: Monthly     Commercial     IFRS Constant   \n",
      "\n",
      "   TotalPremium TotalClaims  \n",
      "0     21.929825         0.0  \n",
      "1     21.929825         0.0  \n",
      "2      0.000000         0.0  \n",
      "3    512.848070         0.0  \n",
      "4      0.000000         0.0  \n",
      "\n",
      "[5 rows x 52 columns]\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# TASK 1: EXPLORATORY DATA ANALYSIS & STATISTICAL THINKING\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TASK 1: EXPLORATORY DATA ANALYSIS & STATISTICAL THINKING\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Load the data\n",
    "print(\"\\n[1.1] Loading data...\")\n",
    "df = pd.read_csv('./Data/MachineLearningRating_v3.txt', sep='|',encoding='utf-8-sig') \n",
    "\n",
    "\n",
    "\n",
    "print(\"Data loaded successfully!\")\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "\n",
    "print(\"\\n[1.2] Data Understanding - Basic Information\")\n",
    "print(\"-\" * 80)\n",
    "print(df.info())\n",
    "print(\"\\nFirst few rows:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6685235d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "FEATURE ENGINEERING AND MODEL BUILDING\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"FEATURE ENGINEERING AND MODEL BUILDING\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 1: COMPREHENSIVE FEATURE ENCODING\n",
    "# ============================================================================\n",
    "\n",
    "def prepare_and_encode_features(df):\n",
    "    \"\"\"\n",
    "    Prepare and encode all features for machine learning\n",
    "    Ensures all data is numeric and compatible with all ML algorithms\n",
    "    \"\"\"\n",
    "    print(\"\\n[Step 1] Preparing and Encoding Features...\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    df_model = df.copy()\n",
    "    \n",
    "    # Create new features\n",
    "    print(\"\\n1.1 Creating derived features...\")\n",
    "    if 'RegistrationYear' in df_model.columns:\n",
    "        df_model['VehicleAge'] = 2015 - df_model['RegistrationYear']\n",
    "    \n",
    "    if 'TotalClaims' in df_model.columns:\n",
    "        df_model['HasClaim'] = (df_model['TotalClaims'] > 0).astype(int)\n",
    "    \n",
    "    if 'TotalPremium' in df_model.columns and 'TotalClaims' in df_model.columns:\n",
    "        df_model['Margin'] = df_model['TotalPremium'] - df_model['TotalClaims']\n",
    "    \n",
    "    # Identify categorical and numerical columns\n",
    "    print(\"\\n1.2 Identifying column types...\")\n",
    "    \n",
    "    # Define categorical columns that need encoding\n",
    "    categorical_cols = []\n",
    "    for col in df_model.columns:\n",
    "        if df_model[col].dtype == 'object':\n",
    "            categorical_cols.append(col)\n",
    "        elif df_model[col].dtype == 'bool':\n",
    "            df_model[col] = df_model[col].astype(int)\n",
    "    \n",
    "    print(f\"Found {len(categorical_cols)} categorical columns\")\n",
    "    \n",
    "    # Encode categorical variables\n",
    "    print(\"\\n1.3 Encoding categorical variables...\")\n",
    "    label_encoders = {}\n",
    "    \n",
    "    for col in categorical_cols:\n",
    "        print(f\"  Encoding: {col}\")\n",
    "        le = LabelEncoder()\n",
    "        # Handle missing values\n",
    "        df_model[col] = df_model[col].fillna('Unknown')\n",
    "        # Encode\n",
    "        df_model[col + '_encoded'] = le.fit_transform(df_model[col].astype(str))\n",
    "        label_encoders[col] = le\n",
    "    \n",
    "    # Handle numerical columns - fill missing values\n",
    "    print(\"\\n1.4 Handling missing values in numerical columns...\")\n",
    "    numerical_cols = df_model.select_dtypes(include=[np.number]).columns\n",
    "    for col in numerical_cols:\n",
    "        if df_model[col].isnull().sum() > 0:\n",
    "            median_val = df_model[col].median()\n",
    "            df_model[col].fillna(median_val, inplace=True)\n",
    "            print(f\"  Filled {col} with median: {median_val:.2f}\")\n",
    "    \n",
    "    print(\"\\nFeature preparation complete!\")\n",
    "    return df_model, categorical_cols, label_encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "323356ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# STEP 2: SELECT FEATURES FOR MODELING\n",
    "# ============================================================================\n",
    "\n",
    "def select_model_features(df_model, categorical_cols):\n",
    "    \"\"\"\n",
    "    Select appropriate features for modeling\n",
    "    \"\"\"\n",
    "    print(\"\\n[Step 2] Selecting Model Features...\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    # Features to use (encoded categorical + numerical)\n",
    "    feature_cols = []\n",
    "    \n",
    "    # Add encoded categorical features\n",
    "    for col in categorical_cols:\n",
    "        if col + '_encoded' in df_model.columns:\n",
    "            feature_cols.append(col + '_encoded')\n",
    "    \n",
    "    # Define important numerical features\n",
    "    important_numerical = [\n",
    "        'VehicleAge', 'SumInsured', 'CalculatedPremiumPerTerm',\n",
    "        'Cylinders', 'cubiccapacity', 'kilowatts', 'NumberOfDoors',\n",
    "        'CustomValueEstimate', 'ExcessSelected'\n",
    "    ]\n",
    "    \n",
    "    # Add numerical features that exist\n",
    "    for col in important_numerical:\n",
    "        if col in df_model.columns:\n",
    "            feature_cols.append(col)\n",
    "    \n",
    "    # Remove any features that shouldn't be used for prediction\n",
    "    exclude_cols = ['TotalClaims', 'TotalPremium', 'Margin', 'HasClaim', \n",
    "                   'PolicyID', 'UnderwrittenCoverID', 'TransactionMonth']\n",
    "    \n",
    "    feature_cols = [col for col in feature_cols if col not in exclude_cols]\n",
    "    \n",
    "    # Ensure all features are numeric\n",
    "    print(\"\\n2.1 Verifying all features are numeric...\")\n",
    "    valid_features = []\n",
    "    for col in feature_cols:\n",
    "        if col in df_model.columns:\n",
    "            if pd.api.types.is_numeric_dtype(df_model[col]):\n",
    "                valid_features.append(col)\n",
    "            else:\n",
    "                print(f\"  ⚠ Skipping non-numeric column: {col} (dtype: {df_model[col].dtype})\")\n",
    "    \n",
    "    feature_cols = valid_features\n",
    "    \n",
    "    print(f\"\\nSelected {len(feature_cols)} features for modeling:\")\n",
    "    for i, col in enumerate(feature_cols[:20], 1):  # Show first 20\n",
    "        print(f\"  {i}. {col}\")\n",
    "    if len(feature_cols) > 20:\n",
    "        print(f\"  ... and {len(feature_cols) - 20} more\")\n",
    "    \n",
    "    return feature_cols\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4f7221d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# STEP 3: BUILD CLAIM SEVERITY MODELS\n",
    "# ============================================================================\n",
    "\n",
    "def build_claim_severity_model(df, feature_cols):\n",
    "    \"\"\"\n",
    "    Build models to predict claim amount for policies with claims\n",
    "    Target: TotalClaims (where TotalClaims > 0)\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"\\n[Step 3] Building Claim Severity Prediction Models...\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Filter to policies with claims\n",
    "    df_claims = df[df['TotalClaims'] > 0].copy()\n",
    "    print(f\"Training on {len(df_claims):,} policies with claims\")\n",
    "    \n",
    "    # Prepare data - ensure all features exist and are numeric\n",
    "    available_features = [col for col in feature_cols if col in df_claims.columns]\n",
    "    print(f\"Using {len(available_features)} features\")\n",
    "    \n",
    "    X = df_claims[available_features].copy()\n",
    "    y = df_claims['TotalClaims'].copy()\n",
    "    \n",
    "    # Final check - ensure no object types\n",
    "    object_cols = X.select_dtypes(include=['object']).columns\n",
    "    if len(object_cols) > 0:\n",
    "        print(f\"\\n⚠ Warning: Found object columns, converting...\")\n",
    "        for col in object_cols:\n",
    "            print(f\"  Converting {col}\")\n",
    "            le = LabelEncoder()\n",
    "            X[col] = le.fit_transform(X[col].astype(str))\n",
    "    \n",
    "    # Fill any remaining NaN values\n",
    "    X = X.fillna(0)\n",
    "    \n",
    "    print(f\"\\nFinal X shape: {X.shape}\")\n",
    "    print(f\"Target y shape: {y.shape}\")\n",
    "    print(f\"X dtypes summary: {X.dtypes.value_counts().to_dict()}\")\n",
    "    \n",
    "    # Split data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nTrain set: {X_train.shape[0]:,} samples\")\n",
    "    print(f\"Test set: {X_test.shape[0]:,} samples\")\n",
    "    \n",
    "    # Scale features for Linear Regression\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    # Dictionary to store models and results\n",
    "    models = {}\n",
    "    results = []\n",
    "    \n",
    "    # 1. Linear Regression\n",
    "    print(\"\\n\" + \"-\"*80)\n",
    "    print(\"1. Training Linear Regression...\")\n",
    "    try:\n",
    "        lr = LinearRegression()\n",
    "        lr.fit(X_train_scaled, y_train)\n",
    "        y_pred_lr = lr.predict(X_test_scaled)\n",
    "        \n",
    "        rmse_lr = np.sqrt(mean_squared_error(y_test, y_pred_lr))\n",
    "        r2_lr = r2_score(y_test, y_pred_lr)\n",
    "        mae_lr = mean_absolute_error(y_test, y_pred_lr)\n",
    "        \n",
    "        models['Linear Regression'] = lr\n",
    "        results.append({\n",
    "            'Model': 'Linear Regression',\n",
    "            'RMSE': rmse_lr,\n",
    "            'R2_Score': r2_lr,\n",
    "            'MAE': mae_lr\n",
    "        })\n",
    "        print(f\"✓ Linear Regression - RMSE: {rmse_lr:,.2f}, R²: {r2_lr:.4f}, MAE: {mae_lr:,.2f}\")\n",
    "    except Exception as e:\n",
    "        print(f\"✗ Linear Regression failed: {str(e)}\")\n",
    "    \n",
    "    # 2. Decision Tree\n",
    "    print(\"\\n\" + \"-\"*80)\n",
    "    print(\"2. Training Decision Tree...\")\n",
    "    try:\n",
    "        dt = DecisionTreeRegressor(max_depth=10, min_samples_split=20, random_state=42)\n",
    "        dt.fit(X_train, y_train)\n",
    "        y_pred_dt = dt.predict(X_test)\n",
    "        \n",
    "        rmse_dt = np.sqrt(mean_squared_error(y_test, y_pred_dt))\n",
    "        r2_dt = r2_score(y_test, y_pred_dt)\n",
    "        mae_dt = mean_absolute_error(y_test, y_pred_dt)\n",
    "        \n",
    "        models['Decision Tree'] = dt\n",
    "        results.append({\n",
    "            'Model': 'Decision Tree',\n",
    "            'RMSE': rmse_dt,\n",
    "            'R2_Score': r2_dt,\n",
    "            'MAE': mae_dt\n",
    "        })\n",
    "        print(f\"✓ Decision Tree - RMSE: {rmse_dt:,.2f}, R²: {r2_dt:.4f}, MAE: {mae_dt:,.2f}\")\n",
    "    except Exception as e:\n",
    "        print(f\"✗ Decision Tree failed: {str(e)}\")\n",
    "    \n",
    "    # 3. Random Forest\n",
    "    print(\"\\n\" + \"-\"*80)\n",
    "    print(\"3. Training Random Forest...\")\n",
    "    try:\n",
    "        rf = RandomForestRegressor(n_estimators=100, max_depth=15, \n",
    "                                   min_samples_split=20, random_state=42, n_jobs=-1)\n",
    "        rf.fit(X_train, y_train)\n",
    "        y_pred_rf = rf.predict(X_test)\n",
    "        \n",
    "        rmse_rf = np.sqrt(mean_squared_error(y_test, y_pred_rf))\n",
    "        r2_rf = r2_score(y_test, y_pred_rf)\n",
    "        mae_rf = mean_absolute_error(y_test, y_pred_rf)\n",
    "        \n",
    "        models['Random Forest'] = rf\n",
    "        results.append({\n",
    "            'Model': 'Random Forest',\n",
    "            'RMSE': rmse_rf,\n",
    "            'R2_Score': r2_rf,\n",
    "            'MAE': mae_rf\n",
    "        })\n",
    "        print(f\"✓ Random Forest - RMSE: {rmse_rf:,.2f}, R²: {r2_rf:.4f}, MAE: {mae_rf:,.2f}\")\n",
    "    except Exception as e:\n",
    "        print(f\"✗ Random Forest failed: {str(e)}\")\n",
    "    \n",
    "    # 4. Gradient Boosting\n",
    "    print(\"\\n\" + \"-\"*80)\n",
    "    print(\"4. Training Gradient Boosting...\")\n",
    "    try:\n",
    "        gb = GradientBoostingRegressor(n_estimators=100, max_depth=5, \n",
    "                                       learning_rate=0.1, random_state=42)\n",
    "        gb.fit(X_train, y_train)\n",
    "        y_pred_gb = gb.predict(X_test)\n",
    "        \n",
    "        rmse_gb = np.sqrt(mean_squared_error(y_test, y_pred_gb))\n",
    "        r2_gb = r2_score(y_test, y_pred_gb)\n",
    "        mae_gb = mean_absolute_error(y_test, y_pred_gb)\n",
    "        \n",
    "        models['Gradient Boosting'] = gb\n",
    "        results.append({\n",
    "            'Model': 'Gradient Boosting',\n",
    "            'RMSE': rmse_gb,\n",
    "            'R2_Score': r2_gb,\n",
    "            'MAE': mae_gb\n",
    "        })\n",
    "        print(f\"✓ Gradient Boosting - RMSE: {rmse_gb:,.2f}, R²: {r2_gb:.4f}, MAE: {mae_gb:,.2f}\")\n",
    "    except Exception as e:\n",
    "        print(f\"✗ Gradient Boosting failed: {str(e)}\")\n",
    "    \n",
    "    # 5. XGBoost\n",
    "    print(\"\\n\" + \"-\"*80)\n",
    "    print(\"5. Training XGBoost...\")\n",
    "    try:\n",
    "        # Ensure X_train and X_test are completely numeric\n",
    "        X_train_xgb = X_train.copy()\n",
    "        X_test_xgb = X_test.copy()\n",
    "        \n",
    "        # Convert all to float\n",
    "        X_train_xgb = X_train_xgb.astype(float)\n",
    "        X_test_xgb = X_test_xgb.astype(float)\n",
    "        \n",
    "        xgb_model = xgb.XGBRegressor(\n",
    "            n_estimators=100, \n",
    "            max_depth=6, \n",
    "            learning_rate=0.1, \n",
    "            random_state=42,\n",
    "            tree_method='hist',  # Use histogram-based algorithm\n",
    "            enable_categorical=False  # Disable categorical features\n",
    "        )\n",
    "        xgb_model.fit(X_train_xgb, y_train)\n",
    "        y_pred_xgb = xgb_model.predict(X_test_xgb)\n",
    "        \n",
    "        rmse_xgb = np.sqrt(mean_squared_error(y_test, y_pred_xgb))\n",
    "        r2_xgb = r2_score(y_test, y_pred_xgb)\n",
    "        mae_xgb = mean_absolute_error(y_test, y_pred_xgb)\n",
    "        \n",
    "        models['XGBoost'] = xgb_model\n",
    "        results.append({\n",
    "            'Model': 'XGBoost',\n",
    "            'RMSE': rmse_xgb,\n",
    "            'R2_Score': r2_xgb,\n",
    "            'MAE': mae_xgb\n",
    "        })\n",
    "        print(f\"✓ XGBoost - RMSE: {rmse_xgb:,.2f}, R²: {r2_xgb:.4f}, MAE: {mae_xgb:,.2f}\")\n",
    "    except Exception as e:\n",
    "        print(f\"✗ XGBoost failed: {str(e)}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "    \n",
    "    # Results comparison\n",
    "    if len(results) > 0:\n",
    "        results_df = pd.DataFrame(results)\n",
    "        results_df = results_df.sort_values('R2_Score', ascending=False)\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"MODEL COMPARISON - CLAIM SEVERITY PREDICTION\")\n",
    "        print(\"=\"*80)\n",
    "        print(results_df.to_string(index=False))\n",
    "        \n",
    "        # Visualize model comparison\n",
    "        fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "        \n",
    "        colors = plt.cm.viridis(np.linspace(0, 1, len(results_df)))\n",
    "        \n",
    "        axes[0].barh(results_df['Model'], results_df['RMSE'], color=colors)\n",
    "        axes[0].set_xlabel('RMSE (lower is better)', fontweight='bold')\n",
    "        axes[0].set_title('Model Comparison: RMSE', fontsize=13, fontweight='bold')\n",
    "        axes[0].invert_yaxis()\n",
    "        axes[0].grid(True, alpha=0.3, axis='x')\n",
    "        \n",
    "        axes[1].barh(results_df['Model'], results_df['R2_Score'], color=colors)\n",
    "        axes[1].set_xlabel('R² Score (higher is better)', fontweight='bold')\n",
    "        axes[1].set_title('Model Comparison: R² Score', fontsize=13, fontweight='bold')\n",
    "        axes[1].invert_yaxis()\n",
    "        axes[1].grid(True, alpha=0.3, axis='x')\n",
    "        axes[1].axvline(x=0, color='red', linestyle='--', alpha=0.5)\n",
    "        \n",
    "        axes[2].barh(results_df['Model'], results_df['MAE'], color=colors)\n",
    "        axes[2].set_xlabel('MAE (lower is better)', fontweight='bold')\n",
    "        axes[2].set_title('Model Comparison: MAE', fontsize=13, fontweight='bold')\n",
    "        axes[2].invert_yaxis()\n",
    "        axes[2].grid(True, alpha=0.3, axis='x')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig('model_comparison_claims.png', dpi=300, bbox_inches='tight')\n",
    "        print(\"\\n✓ Saved: model_comparison_claims.png\")\n",
    "        plt.close()\n",
    "        \n",
    "        return models, results_df, scaler, available_features\n",
    "    else:\n",
    "        print(\"\\n✗ No models trained successfully\")\n",
    "        return None, None, None, available_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9cc55b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# STEP 4: FEATURE IMPORTANCE ANALYSIS\n",
    "# ============================================================================\n",
    "\n",
    "def analyze_feature_importance(model, feature_names, model_name='Model', top_n=20):\n",
    "    \"\"\"Analyze and visualize feature importance\"\"\"\n",
    "    \n",
    "    print(f\"\\n[Step 4] Feature Importance Analysis - {model_name}\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    if hasattr(model, 'feature_importances_'):\n",
    "        importances = model.feature_importances_\n",
    "        \n",
    "        feature_importance = pd.DataFrame({\n",
    "            'Feature': feature_names,\n",
    "            'Importance': importances\n",
    "        }).sort_values('Importance', ascending=False)\n",
    "        \n",
    "        print(f\"\\nTop {top_n} Important Features:\")\n",
    "        print(feature_importance.head(top_n).to_string(index=False))\n",
    "        \n",
    "        # Visualize\n",
    "        plt.figure(figsize=(12, 10))\n",
    "        top_features = feature_importance.head(top_n)\n",
    "        \n",
    "        colors = plt.cm.RdYlGn(np.linspace(0.3, 0.9, len(top_features)))\n",
    "        \n",
    "        plt.barh(range(len(top_features)), top_features['Importance'], color=colors, edgecolor='black')\n",
    "        plt.yticks(range(len(top_features)), top_features['Feature'])\n",
    "        plt.xlabel('Feature Importance', fontsize=12, fontweight='bold')\n",
    "        plt.title(f'Top {top_n} Feature Importances - {model_name}', fontsize=14, fontweight='bold')\n",
    "        plt.gca().invert_yaxis()\n",
    "        plt.grid(True, alpha=0.3, axis='x')\n",
    "        plt.tight_layout()\n",
    "        \n",
    "        filename = f'feature_importance_{model_name.replace(\" \", \"_\")}.png'\n",
    "        plt.savefig(filename, dpi=300, bbox_inches='tight')\n",
    "        print(f\"\\n✓ Saved: {filename}\")\n",
    "        plt.close()\n",
    "        \n",
    "        return feature_importance\n",
    "    else:\n",
    "        print(f\"Model {model_name} does not have feature_importances_ attribute\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f2a4fdd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Step 1] Preparing and Encoding Features...\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "1.1 Creating derived features...\n",
      "\n",
      "1.2 Identifying column types...\n",
      "Found 36 categorical columns\n",
      "\n",
      "1.3 Encoding categorical variables...\n",
      "  Encoding: TransactionMonth\n",
      "  Encoding: Citizenship\n",
      "  Encoding: LegalType\n",
      "  Encoding: Title\n",
      "  Encoding: Language\n",
      "  Encoding: Bank\n",
      "  Encoding: AccountType\n",
      "  Encoding: MaritalStatus\n",
      "  Encoding: Gender\n",
      "  Encoding: Country\n",
      "  Encoding: Province\n",
      "  Encoding: MainCrestaZone\n",
      "  Encoding: SubCrestaZone\n",
      "  Encoding: ItemType\n",
      "  Encoding: VehicleType\n",
      "  Encoding: make\n",
      "  Encoding: Model\n",
      "  Encoding: bodytype\n",
      "  Encoding: VehicleIntroDate\n",
      "  Encoding: AlarmImmobiliser\n",
      "  Encoding: TrackingDevice\n",
      "  Encoding: CapitalOutstanding\n",
      "  Encoding: NewVehicle\n",
      "  Encoding: WrittenOff\n",
      "  Encoding: Rebuilt\n",
      "  Encoding: Converted\n",
      "  Encoding: CrossBorder\n",
      "  Encoding: TermFrequency\n",
      "  Encoding: ExcessSelected\n",
      "  Encoding: CoverCategory\n",
      "  Encoding: CoverType\n",
      "  Encoding: CoverGroup\n",
      "  Encoding: Section\n",
      "  Encoding: Product\n",
      "  Encoding: StatutoryClass\n",
      "  Encoding: StatutoryRiskType\n",
      "\n",
      "1.4 Handling missing values in numerical columns...\n",
      "  Filled mmcode with median: 60058415.00\n",
      "  Filled Cylinders with median: 4.00\n",
      "  Filled cubiccapacity with median: 2694.00\n",
      "  Filled kilowatts with median: 111.00\n",
      "  Filled NumberOfDoors with median: 4.00\n",
      "  Filled CustomValueEstimate with median: 220000.00\n",
      "  Filled NumberOfVehiclesInFleet with median: nan\n",
      "\n",
      "Feature preparation complete!\n"
     ]
    }
   ],
   "source": [
    "df_model, categorical_cols, label_encoders = prepare_and_encode_features(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "97c90cf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Step 2] Selecting Model Features...\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "2.1 Verifying all features are numeric...\n",
      "  ⚠ Skipping non-numeric column: ExcessSelected (dtype: object)\n",
      "\n",
      "Selected 44 features for modeling:\n",
      "  1. TransactionMonth_encoded\n",
      "  2. Citizenship_encoded\n",
      "  3. LegalType_encoded\n",
      "  4. Title_encoded\n",
      "  5. Language_encoded\n",
      "  6. Bank_encoded\n",
      "  7. AccountType_encoded\n",
      "  8. MaritalStatus_encoded\n",
      "  9. Gender_encoded\n",
      "  10. Country_encoded\n",
      "  11. Province_encoded\n",
      "  12. MainCrestaZone_encoded\n",
      "  13. SubCrestaZone_encoded\n",
      "  14. ItemType_encoded\n",
      "  15. VehicleType_encoded\n",
      "  16. make_encoded\n",
      "  17. Model_encoded\n",
      "  18. bodytype_encoded\n",
      "  19. VehicleIntroDate_encoded\n",
      "  20. AlarmImmobiliser_encoded\n",
      "  ... and 24 more\n"
     ]
    }
   ],
   "source": [
    "feature_cols = select_model_features(df_model, categorical_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0fc35327",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Step 3] Building Claim Severity Prediction Models...\n",
      "================================================================================\n",
      "Training on 2,788 policies with claims\n",
      "Using 44 features\n",
      "\n",
      "Final X shape: (2788, 44)\n",
      "Target y shape: (2788,)\n",
      "X dtypes summary: {dtype('int64'): 37, dtype('float64'): 7}\n",
      "\n",
      "Train set: 2,230 samples\n",
      "Test set: 558 samples\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1. Training Linear Regression...\n",
      "✓ Linear Regression - RMSE: 33,799.34, R²: 0.2897, MAE: 17,911.45\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "2. Training Decision Tree...\n",
      "✓ Decision Tree - RMSE: 37,228.65, R²: 0.1382, MAE: 17,055.66\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "3. Training Random Forest...\n",
      "✓ Random Forest - RMSE: 34,953.47, R²: 0.2403, MAE: 16,219.32\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4. Training Gradient Boosting...\n",
      "✓ Gradient Boosting - RMSE: 38,263.07, R²: 0.0897, MAE: 17,082.29\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5. Training XGBoost...\n",
      "✓ XGBoost - RMSE: 38,934.89, R²: 0.0574, MAE: 17,535.78\n",
      "\n",
      "================================================================================\n",
      "MODEL COMPARISON - CLAIM SEVERITY PREDICTION\n",
      "================================================================================\n",
      "            Model         RMSE  R2_Score          MAE\n",
      "Linear Regression 33799.339554  0.289665 17911.445413\n",
      "    Random Forest 34953.465089  0.240326 16219.320126\n",
      "    Decision Tree 37228.648614  0.138210 17055.664959\n",
      "Gradient Boosting 38263.072269  0.089654 17082.286643\n",
      "          XGBoost 38934.885499  0.057406 17535.782206\n",
      "\n",
      "✓ Saved: model_comparison_claims.png\n"
     ]
    }
   ],
   "source": [
    "models, results_df, scaler, features_used = build_claim_severity_model(df_model, feature_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2f7da438",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Step 4] Feature Importance Analysis - Random_Forest\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Top 20 Important Features:\n",
      "                   Feature  Importance\n",
      "  CalculatedPremiumPerTerm    0.344833\n",
      "                SumInsured    0.217418\n",
      "       CustomValueEstimate    0.072077\n",
      "CapitalOutstanding_encoded    0.071502\n",
      "       VehicleType_encoded    0.033473\n",
      "  TransactionMonth_encoded    0.031686\n",
      "                 kilowatts    0.026276\n",
      "                VehicleAge    0.022002\n",
      "             cubiccapacity    0.020729\n",
      "     SubCrestaZone_encoded    0.019388\n",
      "             Model_encoded    0.015569\n",
      "  VehicleIntroDate_encoded    0.014051\n",
      "              make_encoded    0.012248\n",
      "          Province_encoded    0.011503\n",
      "             Title_encoded    0.011310\n",
      "     CoverCategory_encoded    0.010041\n",
      "              Bank_encoded    0.009564\n",
      "    MainCrestaZone_encoded    0.009282\n",
      "          bodytype_encoded    0.008444\n",
      "             NumberOfDoors    0.006870\n",
      "\n",
      "✓ Saved: feature_importance_Random_Forest.png\n"
     ]
    }
   ],
   "source": [
    "if models and 'Random Forest' in models:\n",
    "    fi_rf = analyze_feature_importance(models['Random Forest'], features_used, 'Random_Forest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a28bc20e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[4.7] Model Interpretation with SHAP (Advanced)\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n[4.7] Model Interpretation with SHAP (Advanced)\")\n",
    "print(\"-\" * 80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv (3.13.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
